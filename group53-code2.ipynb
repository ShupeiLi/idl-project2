{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1614d13",
   "metadata": {},
   "source": [
    "# Assignment 2: Building MLPs, CNNs, and Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2fa644",
   "metadata": {},
   "source": [
    "## Task 1: Learn the basics of Keras API for Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006843a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92b98f73",
   "metadata": {},
   "source": [
    "## Task 2: Develop a \"Tell-the-time\" network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2755afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19402e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47eb7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"./a2_data/images.npy\")\n",
    "label = np.load(\"./a2_data/labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf715a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data/255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da8c83",
   "metadata": {},
   "source": [
    "Regression Task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "435c5ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_r=label[:,0]+label[:,1]/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88be9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_reg(y_true, y_pred):\n",
    "    d = K.abs(y_true-y_pred)\n",
    "    return (1-(d//6))*(d)+(d//6)*(12-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4bb78af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (14400, 150, 150)\n",
      "Test set: (3600, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "X, X_test, y, y_test = train_test_split(data, label_r, test_size=0.2, random_state=42)\n",
    "print(f\"Train set: {X.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a7c68db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 148, 148, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 36, 36, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 18, 18, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 8, 8, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,929\n",
      "Trainable params: 72,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regression_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(150,150,1)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\",strides=2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64,activation=\"relu\"),\n",
    "        layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "regression_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "830ef99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 60\n",
    "regression_model.compile(loss=\"mse\", optimizer=\"adam\", metrics=common_sense_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28a0ef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "203/203 [==============================] - 5s 19ms/step - loss: 13.7863 - common_sense_reg: 3.0049 - val_loss: 12.3277 - val_common_sense_reg: 3.0180\n",
      "Epoch 2/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 12.1149 - common_sense_reg: 2.9987 - val_loss: 11.9883 - val_common_sense_reg: 2.9832\n",
      "Epoch 3/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 11.7883 - common_sense_reg: 2.9071 - val_loss: 10.9861 - val_common_sense_reg: 2.7747\n",
      "Epoch 4/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 10.5699 - common_sense_reg: 2.6683 - val_loss: 10.0905 - val_common_sense_reg: 2.5747\n",
      "Epoch 5/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 9.7920 - common_sense_reg: 2.4883 - val_loss: 9.7146 - val_common_sense_reg: 2.4516\n",
      "Epoch 6/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 9.4181 - common_sense_reg: 2.4291 - val_loss: 9.0243 - val_common_sense_reg: 2.3464\n",
      "Epoch 7/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 9.0144 - common_sense_reg: 2.3614 - val_loss: 9.6056 - val_common_sense_reg: 2.3529\n",
      "Epoch 8/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 8.7500 - common_sense_reg: 2.3121 - val_loss: 8.4847 - val_common_sense_reg: 2.2380\n",
      "Epoch 9/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 8.5698 - common_sense_reg: 2.2728 - val_loss: 8.4630 - val_common_sense_reg: 2.2552\n",
      "Epoch 10/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 8.0889 - common_sense_reg: 2.2088 - val_loss: 8.2268 - val_common_sense_reg: 2.1907\n",
      "Epoch 11/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 7.9243 - common_sense_reg: 2.1727 - val_loss: 8.0989 - val_common_sense_reg: 2.1804\n",
      "Epoch 12/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 7.4923 - common_sense_reg: 2.1144 - val_loss: 7.5364 - val_common_sense_reg: 2.0734\n",
      "Epoch 13/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 7.1705 - common_sense_reg: 2.0634 - val_loss: 7.4696 - val_common_sense_reg: 2.0487\n",
      "Epoch 14/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 7.0835 - common_sense_reg: 2.0419 - val_loss: 7.3953 - val_common_sense_reg: 2.0650\n",
      "Epoch 15/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 6.7778 - common_sense_reg: 1.9916 - val_loss: 7.5930 - val_common_sense_reg: 1.9991\n",
      "Epoch 16/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 6.5732 - common_sense_reg: 1.9511 - val_loss: 6.8020 - val_common_sense_reg: 1.9470\n",
      "Epoch 17/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 6.4959 - common_sense_reg: 1.9397 - val_loss: 6.9262 - val_common_sense_reg: 1.9954\n",
      "Epoch 18/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 6.2614 - common_sense_reg: 1.9054 - val_loss: 6.7320 - val_common_sense_reg: 1.9413\n",
      "Epoch 19/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 6.1197 - common_sense_reg: 1.8743 - val_loss: 6.4548 - val_common_sense_reg: 1.8784\n",
      "Epoch 20/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 5.9078 - common_sense_reg: 1.8363 - val_loss: 6.6098 - val_common_sense_reg: 1.9125\n",
      "Epoch 21/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 5.8219 - common_sense_reg: 1.8244 - val_loss: 6.5772 - val_common_sense_reg: 1.9010\n",
      "Epoch 22/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 5.6321 - common_sense_reg: 1.7848 - val_loss: 6.2357 - val_common_sense_reg: 1.8392\n",
      "Epoch 23/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 5.5562 - common_sense_reg: 1.7721 - val_loss: 6.1607 - val_common_sense_reg: 1.8290\n",
      "Epoch 24/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 5.3090 - common_sense_reg: 1.7265 - val_loss: 5.7778 - val_common_sense_reg: 1.7757\n",
      "Epoch 25/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 5.2219 - common_sense_reg: 1.7073 - val_loss: 5.9621 - val_common_sense_reg: 1.7666\n",
      "Epoch 26/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 5.0756 - common_sense_reg: 1.6811 - val_loss: 5.7179 - val_common_sense_reg: 1.7640\n",
      "Epoch 27/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 4.9130 - common_sense_reg: 1.6443 - val_loss: 5.5041 - val_common_sense_reg: 1.7239\n",
      "Epoch 28/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 4.7759 - common_sense_reg: 1.6271 - val_loss: 5.7314 - val_common_sense_reg: 1.7856\n",
      "Epoch 29/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 4.5846 - common_sense_reg: 1.5884 - val_loss: 5.3670 - val_common_sense_reg: 1.6894\n",
      "Epoch 30/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 4.6013 - common_sense_reg: 1.6013 - val_loss: 5.3817 - val_common_sense_reg: 1.7087\n",
      "Epoch 31/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 4.2795 - common_sense_reg: 1.5291 - val_loss: 5.0083 - val_common_sense_reg: 1.6231\n",
      "Epoch 32/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 4.1870 - common_sense_reg: 1.5129 - val_loss: 5.1330 - val_common_sense_reg: 1.6849\n",
      "Epoch 33/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 4.0032 - common_sense_reg: 1.4755 - val_loss: 4.7737 - val_common_sense_reg: 1.5710\n",
      "Epoch 34/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 3.8810 - common_sense_reg: 1.4503 - val_loss: 4.7189 - val_common_sense_reg: 1.5583\n",
      "Epoch 35/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 3.7998 - common_sense_reg: 1.4379 - val_loss: 4.7455 - val_common_sense_reg: 1.5844\n",
      "Epoch 36/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 3.7042 - common_sense_reg: 1.4191 - val_loss: 4.5748 - val_common_sense_reg: 1.5480\n",
      "Epoch 37/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 3.5263 - common_sense_reg: 1.3848 - val_loss: 4.4443 - val_common_sense_reg: 1.5284\n",
      "Epoch 38/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 3.4078 - common_sense_reg: 1.3640 - val_loss: 4.4775 - val_common_sense_reg: 1.5379\n",
      "Epoch 39/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 3.2634 - common_sense_reg: 1.3358 - val_loss: 4.4530 - val_common_sense_reg: 1.5223\n",
      "Epoch 40/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 3.2001 - common_sense_reg: 1.3229 - val_loss: 4.3054 - val_common_sense_reg: 1.4991\n",
      "Epoch 41/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 3.0849 - common_sense_reg: 1.3021 - val_loss: 4.2173 - val_common_sense_reg: 1.4754\n",
      "Epoch 42/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 3.0017 - common_sense_reg: 1.2842 - val_loss: 4.4353 - val_common_sense_reg: 1.5208\n",
      "Epoch 43/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.9005 - common_sense_reg: 1.2599 - val_loss: 4.3019 - val_common_sense_reg: 1.4990\n",
      "Epoch 44/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.8110 - common_sense_reg: 1.2444 - val_loss: 3.9225 - val_common_sense_reg: 1.4243\n",
      "Epoch 45/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.6986 - common_sense_reg: 1.2196 - val_loss: 3.9701 - val_common_sense_reg: 1.4359\n",
      "Epoch 46/60\n",
      "203/203 [==============================] - 3s 17ms/step - loss: 2.7321 - common_sense_reg: 1.2305 - val_loss: 4.3264 - val_common_sense_reg: 1.4446\n",
      "Epoch 47/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.5895 - common_sense_reg: 1.1927 - val_loss: 3.8724 - val_common_sense_reg: 1.4190\n",
      "Epoch 48/60\n",
      "203/203 [==============================] - 3s 17ms/step - loss: 2.5227 - common_sense_reg: 1.1853 - val_loss: 4.1372 - val_common_sense_reg: 1.4520\n",
      "Epoch 49/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.5726 - common_sense_reg: 1.1973 - val_loss: 4.3031 - val_common_sense_reg: 1.4915\n",
      "Epoch 50/60\n",
      "203/203 [==============================] - 3s 17ms/step - loss: 2.4372 - common_sense_reg: 1.1658 - val_loss: 3.8232 - val_common_sense_reg: 1.3944\n",
      "Epoch 51/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.3150 - common_sense_reg: 1.1316 - val_loss: 3.9273 - val_common_sense_reg: 1.4203\n",
      "Epoch 52/60\n",
      "203/203 [==============================] - 3s 17ms/step - loss: 2.3149 - common_sense_reg: 1.1374 - val_loss: 3.8043 - val_common_sense_reg: 1.3862\n",
      "Epoch 53/60\n",
      "203/203 [==============================] - 3s 17ms/step - loss: 2.2854 - common_sense_reg: 1.1304 - val_loss: 3.7854 - val_common_sense_reg: 1.3870\n",
      "Epoch 54/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.1554 - common_sense_reg: 1.0917 - val_loss: 3.7583 - val_common_sense_reg: 1.3787\n",
      "Epoch 55/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.1889 - common_sense_reg: 1.1047 - val_loss: 3.7220 - val_common_sense_reg: 1.3808\n",
      "Epoch 56/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.0805 - common_sense_reg: 1.0757 - val_loss: 4.0564 - val_common_sense_reg: 1.4118\n",
      "Epoch 57/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.0102 - common_sense_reg: 1.0596 - val_loss: 3.7741 - val_common_sense_reg: 1.3983\n",
      "Epoch 58/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 2.0394 - common_sense_reg: 1.0723 - val_loss: 3.7180 - val_common_sense_reg: 1.3774\n",
      "Epoch 59/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 1.9311 - common_sense_reg: 1.0445 - val_loss: 3.7679 - val_common_sense_reg: 1.4081\n",
      "Epoch 60/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 1.9467 - common_sense_reg: 1.0470 - val_loss: 3.9400 - val_common_sense_reg: 1.4054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18256585b48>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.fit(X,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40b8237b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 4ms/step - loss: 4.0751 - common_sense_reg: 1.4781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.0750956535339355, 1.4780513048171997]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f401f7",
   "metadata": {},
   "source": [
    "Classfication Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7fda48",
   "metadata": {},
   "source": [
    "24 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faf7d8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c71c7128",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c=[]\n",
    "for i in range(24):\n",
    "    la=np.zeros(24)\n",
    "    la[i]=la[i]+1\n",
    "    for j in range(750):\n",
    "        y_c.append(la)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b7fc567",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c=np.stack(y_c)\n",
    "y_c=np.array(y_c,dtype=np.int32)\n",
    "y_c=np.concatenate((y_c,label),axis=1)\n",
    "X, X_test, y, y_test = train_test_split(data, y_c, test_size=0.2, random_state=42)\n",
    "y=y[:,:24]\n",
    "y_test=y_test[:,24:]\n",
    "print(f\"Train set: {X.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "148b9d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 148, 148, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 74, 74, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 36, 36, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 18, 18, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,064\n",
      "Trainable params: 287,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(150,150,1)),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",strides=2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64,activation=keras.layers.LeakyReLU(alpha=0.01)),\n",
    "        layers.Dense(24,activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2920fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 40\n",
    "classification_model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,), metrics=\"accuracy\", run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b146d1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 3.1789 - accuracy: 0.0394 - val_loss: 3.1782 - val_accuracy: 0.0389\n",
      "Epoch 2/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 3.1782 - accuracy: 0.0402 - val_loss: 3.1794 - val_accuracy: 0.0410\n",
      "Epoch 3/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 3.1781 - accuracy: 0.0403 - val_loss: 3.1779 - val_accuracy: 0.0410\n",
      "Epoch 4/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 3.1419 - accuracy: 0.0549 - val_loss: 3.0162 - val_accuracy: 0.0743\n",
      "Epoch 5/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 2.7290 - accuracy: 0.1331 - val_loss: 2.4894 - val_accuracy: 0.1708\n",
      "Epoch 6/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 2.2770 - accuracy: 0.2418 - val_loss: 2.2210 - val_accuracy: 0.2264\n",
      "Epoch 7/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 1.9315 - accuracy: 0.3410 - val_loss: 1.9384 - val_accuracy: 0.3153\n",
      "Epoch 8/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 1.6119 - accuracy: 0.4432 - val_loss: 1.6946 - val_accuracy: 0.4111\n",
      "Epoch 9/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 1.3808 - accuracy: 0.5250 - val_loss: 1.5711 - val_accuracy: 0.4382\n",
      "Epoch 10/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 1.1626 - accuracy: 0.5961 - val_loss: 1.3997 - val_accuracy: 0.4965\n",
      "Epoch 11/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.9767 - accuracy: 0.6613 - val_loss: 1.3195 - val_accuracy: 0.5458\n",
      "Epoch 12/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.8299 - accuracy: 0.7072 - val_loss: 1.2651 - val_accuracy: 0.5472\n",
      "Epoch 13/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.7008 - accuracy: 0.7560 - val_loss: 1.2230 - val_accuracy: 0.5764\n",
      "Epoch 14/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.5951 - accuracy: 0.7892 - val_loss: 1.2102 - val_accuracy: 0.5965\n",
      "Epoch 15/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.5201 - accuracy: 0.8211 - val_loss: 1.1907 - val_accuracy: 0.6042\n",
      "Epoch 16/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.4554 - accuracy: 0.8382 - val_loss: 1.1558 - val_accuracy: 0.6292\n",
      "Epoch 17/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.3724 - accuracy: 0.8714 - val_loss: 1.2508 - val_accuracy: 0.6271\n",
      "Epoch 18/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.3195 - accuracy: 0.8938 - val_loss: 1.2796 - val_accuracy: 0.6229\n",
      "Epoch 19/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.2837 - accuracy: 0.9037 - val_loss: 1.2730 - val_accuracy: 0.6458\n",
      "Epoch 20/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.2486 - accuracy: 0.9160 - val_loss: 1.2857 - val_accuracy: 0.6604\n",
      "Epoch 21/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.1995 - accuracy: 0.9353 - val_loss: 1.3194 - val_accuracy: 0.6472\n",
      "Epoch 22/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.1894 - accuracy: 0.9382 - val_loss: 1.3054 - val_accuracy: 0.6667\n",
      "Epoch 23/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.1571 - accuracy: 0.9495 - val_loss: 1.3245 - val_accuracy: 0.6785\n",
      "Epoch 24/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.1366 - accuracy: 0.9598 - val_loss: 1.4359 - val_accuracy: 0.6778\n",
      "Epoch 25/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.1238 - accuracy: 0.9613 - val_loss: 1.5311 - val_accuracy: 0.6667\n",
      "Epoch 26/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0969 - accuracy: 0.9721 - val_loss: 1.5452 - val_accuracy: 0.6611\n",
      "Epoch 27/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.1066 - accuracy: 0.9669 - val_loss: 1.5990 - val_accuracy: 0.6632\n",
      "Epoch 28/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.1117 - accuracy: 0.9657 - val_loss: 1.5967 - val_accuracy: 0.6736\n",
      "Epoch 29/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.1231 - accuracy: 0.9588 - val_loss: 1.6711 - val_accuracy: 0.6569\n",
      "Epoch 30/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.1059 - accuracy: 0.9674 - val_loss: 1.6152 - val_accuracy: 0.6882\n",
      "Epoch 31/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0780 - accuracy: 0.9773 - val_loss: 1.6654 - val_accuracy: 0.6875\n",
      "Epoch 32/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0601 - accuracy: 0.9833 - val_loss: 1.5389 - val_accuracy: 0.7028\n",
      "Epoch 33/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.0590 - accuracy: 0.9840 - val_loss: 1.7399 - val_accuracy: 0.6750\n",
      "Epoch 34/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.0649 - accuracy: 0.9815 - val_loss: 1.7061 - val_accuracy: 0.6826\n",
      "Epoch 35/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0503 - accuracy: 0.9875 - val_loss: 1.7800 - val_accuracy: 0.6944\n",
      "Epoch 36/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0423 - accuracy: 0.9884 - val_loss: 1.8367 - val_accuracy: 0.6757\n",
      "Epoch 37/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0550 - accuracy: 0.9840 - val_loss: 1.8891 - val_accuracy: 0.6889\n",
      "Epoch 38/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.0749 - accuracy: 0.9762 - val_loss: 1.9014 - val_accuracy: 0.6847\n",
      "Epoch 39/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.1393 - accuracy: 0.9555 - val_loss: 1.8926 - val_accuracy: 0.6646\n",
      "Epoch 40/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.1007 - accuracy: 0.9685 - val_loss: 1.7395 - val_accuracy: 0.6924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bfab7f6f48>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.fit(X,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48a347ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "output=classification_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00e6a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_reg(y_true, y_pred):\n",
    "    d = np.abs(y_true-y_pred)\n",
    "    return (1-(d//6))*(d)+(d//6)*(12-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f40a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=output.argmax(axis=1)\n",
    "output=output*((720/24)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5865536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test[:,0]+y_test[:,1]/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ae0e594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6205694444444445"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_sense_reg(y_test,output).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768cfdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13f1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96067e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2df1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a352e0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f981c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230dae88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f1b009e",
   "metadata": {},
   "source": [
    "72 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e786e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "546d5066",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c=[]\n",
    "for i in range(72):\n",
    "    la=np.zeros(72)\n",
    "    la[i]=la[i]+1\n",
    "    for j in range(250):\n",
    "        y_c.append(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2893096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (14400, 150, 150)\n",
      "Test set: (3600, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "y_c=np.stack(y_c)\n",
    "y_c=np.array(y_c,dtype=np.int32)\n",
    "y_c=np.concatenate((y_c,label),axis=1)\n",
    "X, X_test, y, y_test = train_test_split(data, y_c, test_size=0.2, random_state=42)\n",
    "y=y[:,:72]\n",
    "y_test=y_test[:,72:]\n",
    "print(f\"Train set: {X.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "326400d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 36, 36, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 18, 18, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 72)                4680      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 290,184\n",
      "Trainable params: 290,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(150,150,1)),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",strides=2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64,activation=keras.layers.LeakyReLU(alpha=0.01)),\n",
    "        layers.Dense(72,activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddecadfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 40\n",
    "classification_model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,), metrics=\"accuracy\", run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b510270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "102/102 [==============================] - 8s 42ms/step - loss: 4.2780 - accuracy: 0.0122 - val_loss: 4.2771 - val_accuracy: 0.0188\n",
      "Epoch 2/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 4.2768 - accuracy: 0.0144 - val_loss: 4.2774 - val_accuracy: 0.0104\n",
      "Epoch 3/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 4.2767 - accuracy: 0.0130 - val_loss: 4.2776 - val_accuracy: 0.0090\n",
      "Epoch 4/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 4.2766 - accuracy: 0.0124 - val_loss: 4.2780 - val_accuracy: 0.0188\n",
      "Epoch 5/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 4.2767 - accuracy: 0.0133 - val_loss: 4.2780 - val_accuracy: 0.0181\n",
      "Epoch 6/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 4.2767 - accuracy: 0.0130 - val_loss: 4.2783 - val_accuracy: 0.0160\n",
      "Epoch 7/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 4.2765 - accuracy: 0.0139 - val_loss: 4.2786 - val_accuracy: 0.0090\n",
      "Epoch 8/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 4.2766 - accuracy: 0.0128 - val_loss: 4.2786 - val_accuracy: 0.0132\n",
      "Epoch 9/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 4.2764 - accuracy: 0.0146 - val_loss: 4.2790 - val_accuracy: 0.0090\n",
      "Epoch 10/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 4.2765 - accuracy: 0.0135 - val_loss: 4.2790 - val_accuracy: 0.0090\n",
      "Epoch 11/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 4.2765 - accuracy: 0.0141 - val_loss: 4.2791 - val_accuracy: 0.0111\n",
      "Epoch 12/40\n",
      "102/102 [==============================] - 4s 42ms/step - loss: 4.2765 - accuracy: 0.0130 - val_loss: 4.2793 - val_accuracy: 0.0090\n",
      "Epoch 13/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 4.2765 - accuracy: 0.0144 - val_loss: 4.2794 - val_accuracy: 0.0111\n",
      "Epoch 14/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 4.2764 - accuracy: 0.0149 - val_loss: 4.2785 - val_accuracy: 0.0076\n",
      "Epoch 15/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 4.2375 - accuracy: 0.0218 - val_loss: 4.1529 - val_accuracy: 0.0333\n",
      "Epoch 16/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 3.7401 - accuracy: 0.0788 - val_loss: 3.3849 - val_accuracy: 0.1146\n",
      "Epoch 17/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 3.0391 - accuracy: 0.1681 - val_loss: 2.8612 - val_accuracy: 0.1819\n",
      "Epoch 18/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 2.6036 - accuracy: 0.2480 - val_loss: 2.5363 - val_accuracy: 0.2438\n",
      "Epoch 19/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 2.2458 - accuracy: 0.3255 - val_loss: 2.2804 - val_accuracy: 0.3000\n",
      "Epoch 20/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 1.9703 - accuracy: 0.3796 - val_loss: 2.1029 - val_accuracy: 0.3306\n",
      "Epoch 21/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 1.7437 - accuracy: 0.4339 - val_loss: 1.9671 - val_accuracy: 0.3576\n",
      "Epoch 22/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 1.5495 - accuracy: 0.4904 - val_loss: 1.8515 - val_accuracy: 0.3826\n",
      "Epoch 23/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 1.4055 - accuracy: 0.5265 - val_loss: 1.7988 - val_accuracy: 0.3938\n",
      "Epoch 24/40\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 1.2723 - accuracy: 0.5644 - val_loss: 1.7226 - val_accuracy: 0.4306\n",
      "Epoch 25/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 1.1474 - accuracy: 0.6046 - val_loss: 1.7301 - val_accuracy: 0.4222\n",
      "Epoch 26/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 1.0491 - accuracy: 0.6397 - val_loss: 1.6485 - val_accuracy: 0.4563\n",
      "Epoch 27/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.9474 - accuracy: 0.6659 - val_loss: 1.6586 - val_accuracy: 0.4479\n",
      "Epoch 28/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.8767 - accuracy: 0.6941 - val_loss: 1.6177 - val_accuracy: 0.4819\n",
      "Epoch 29/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.7907 - accuracy: 0.7187 - val_loss: 1.6419 - val_accuracy: 0.4882\n",
      "Epoch 30/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.7222 - accuracy: 0.7461 - val_loss: 1.6148 - val_accuracy: 0.4875\n",
      "Epoch 31/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.6612 - accuracy: 0.7649 - val_loss: 1.6221 - val_accuracy: 0.5042\n",
      "Epoch 32/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.6163 - accuracy: 0.7816 - val_loss: 1.7127 - val_accuracy: 0.4993\n",
      "Epoch 33/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.5515 - accuracy: 0.8062 - val_loss: 1.6899 - val_accuracy: 0.5118\n",
      "Epoch 34/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.5228 - accuracy: 0.8150 - val_loss: 1.7184 - val_accuracy: 0.5326\n",
      "Epoch 35/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.4669 - accuracy: 0.8376 - val_loss: 1.7164 - val_accuracy: 0.5340\n",
      "Epoch 36/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.4325 - accuracy: 0.8481 - val_loss: 1.7900 - val_accuracy: 0.5139\n",
      "Epoch 37/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.4065 - accuracy: 0.8579 - val_loss: 1.8224 - val_accuracy: 0.5188\n",
      "Epoch 38/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.3682 - accuracy: 0.8748 - val_loss: 1.9305 - val_accuracy: 0.5208\n",
      "Epoch 39/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.3416 - accuracy: 0.8813 - val_loss: 1.9147 - val_accuracy: 0.5396\n",
      "Epoch 40/40\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.3047 - accuracy: 0.8962 - val_loss: 1.8728 - val_accuracy: 0.5424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2008851cb48>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.fit(X,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3705c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "output=classification_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95c19dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=output.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8d40ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=output*((720/72)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2614d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_reg(y_true, y_pred):\n",
    "    d = np.abs(y_true-y_pred)\n",
    "    return (1-(d//6))*(d)+(d//6)*(12-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f54eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test[:,0]+y_test[:,1]/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "332c5fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9516990740740743"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_sense_reg(y_test,output).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f348ef01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8b3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adddf62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fc14bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2ecfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be22059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf933f74",
   "metadata": {},
   "source": [
    "720 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0da9d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "115db761",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c=[]\n",
    "for i in range(720):\n",
    "    la=np.zeros(720)\n",
    "    la[i]=la[i]+1\n",
    "    for j in range(25):\n",
    "        y_c.append(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc2012b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (14400, 150, 150)\n",
      "Test set: (3600, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "y_c=np.stack(y_c)\n",
    "y_c=np.array(y_c,dtype=np.int32)\n",
    "y_c=np.concatenate((y_c,label),axis=1)\n",
    "X, X_test, y, y_test = train_test_split(data, y_c, test_size=0.2, random_state=42)\n",
    "y=y[:,:720]\n",
    "y_test=y_test[:,720:]\n",
    "print(f\"Train set: {X.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d1ffb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 148, 148, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 74, 74, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 36, 36, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 18, 18, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 720)               46800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332,304\n",
      "Trainable params: 332,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(150,150,1)),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",strides=2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64,activation=\"relu\"),\n",
    "        layers.Dense(720,activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c446203",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "classification_model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,), metrics=\"accuracy\", run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c08e78b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 6.5805 - accuracy: 6.9444e-04 - val_loss: 6.5812 - val_accuracy: 6.9444e-04\n",
      "Epoch 2/20\n",
      "102/102 [==============================] - 4s 42ms/step - loss: 6.5792 - accuracy: 9.2593e-04 - val_loss: 6.5830 - val_accuracy: 6.9444e-04\n",
      "Epoch 3/20\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 6.5786 - accuracy: 0.0015 - val_loss: 6.5848 - val_accuracy: 6.9444e-04\n",
      "Epoch 4/20\n",
      "102/102 [==============================] - 4s 42ms/step - loss: 6.5781 - accuracy: 9.2593e-04 - val_loss: 6.5866 - val_accuracy: 6.9444e-04\n",
      "Epoch 5/20\n",
      "102/102 [==============================] - 4s 42ms/step - loss: 6.5777 - accuracy: 0.0015 - val_loss: 6.5889 - val_accuracy: 0.0014\n",
      "Epoch 6/20\n",
      "102/102 [==============================] - 4s 42ms/step - loss: 6.5771 - accuracy: 0.0015 - val_loss: 6.5906 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "102/102 [==============================] - 4s 42ms/step - loss: 6.5766 - accuracy: 0.0016 - val_loss: 6.5930 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "102/102 [==============================] - 4s 42ms/step - loss: 6.5761 - accuracy: 0.0012 - val_loss: 6.5955 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 6.5757 - accuracy: 0.0015 - val_loss: 6.5983 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 6.5753 - accuracy: 0.0019 - val_loss: 6.6010 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "102/102 [==============================] - 4s 42ms/step - loss: 6.5749 - accuracy: 0.0019 - val_loss: 6.6038 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 6.5746 - accuracy: 0.0018 - val_loss: 6.6065 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 6.5743 - accuracy: 0.0016 - val_loss: 6.6090 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 6.5741 - accuracy: 0.0019 - val_loss: 6.6110 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 6.5741 - accuracy: 0.0018 - val_loss: 6.6125 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 6.5737 - accuracy: 0.0019 - val_loss: 6.6152 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 6.5736 - accuracy: 0.0017 - val_loss: 6.6163 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "102/102 [==============================] - 4s 39ms/step - loss: 6.5735 - accuracy: 0.0019 - val_loss: 6.6190 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 6.5733 - accuracy: 0.0019 - val_loss: 6.6185 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 6.5735 - accuracy: 0.0019 - val_loss: 6.6191 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18104324788>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.fit(X,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78b6320a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "output=classification_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90c978cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=output.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a801108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=output*((720/720)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "354ce709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_reg(y_true, y_pred):\n",
    "    d = np.abs(y_true-y_pred)\n",
    "    return (1-(d//6))*(d)+(d//6)*(12-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33336f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test[:,0]+y_test[:,1]/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "863ef5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.030875"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_sense_reg(y_test,output).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ca269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb89336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9109525",
   "metadata": {},
   "source": [
    "Multi-head models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831161ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081068d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       ...,\n",
       "       [11, 59],\n",
       "       [11, 59],\n",
       "       [11, 59]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "567a3b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (14400, 150, 150)\n",
      "Test set: (3600, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "X, X_test, y, y_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "print(f\"Train set: {X.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e9f360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0109b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2=y[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9071ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=tf.keras.utils.to_categorical(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "630b4345",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2=y2/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccf6a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test[:,0]+y_test[:,1]/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fccc699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multihead_model():\n",
    "    in_put = layers.Input((150, 150, 1))\n",
    "    x = layers.Conv2D(16, (3, 3), activation=\"relu\")(in_put)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(32, (3, 3), activation=\"relu\", strides=(2, 2))(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x1 = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x1 = layers.Dense(12, activation=\"softmax\",name=\"output1\")(x1)\n",
    "    x2 = layers.Dense(64,activation=\"relu\")(x)\n",
    "    x2 = layers.Dense(1,name=\"output2\")(x2)\n",
    "    model = tf.keras.Model(in_put, [x1,x2])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f7cc190",
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_model=multihead_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1f71bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 150, 150, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 148, 148, 16  160         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 74, 74, 16)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 36, 36, 32)   4640        ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 18, 18, 32)  0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 16, 64)   18496       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 64)    0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 4096)         0           ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           262208      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 64)           262208      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " output1 (Dense)                (None, 12)           780         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " output2 (Dense)                (None, 1)            65          ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 548,557\n",
      "Trainable params: 548,557\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "multihead_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1871d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "multihead_model.compile(loss={\"output1\":\"categorical_crossentropy\",\"output2\":\"mse\"},loss_weights={\"output1\":1,\"output2\":1}, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,), metrics={\"output1\":\"accuracy\",\"output2\":\"mse\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "faa37d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "102/102 [==============================] - 3s 33ms/step - loss: 1.0608 - output1_loss: 1.0297 - output2_loss: 0.0312 - output1_accuracy: 0.5890 - output2_mse: 0.0312 - val_loss: 1.2802 - val_output1_loss: 1.2347 - val_output2_loss: 0.0455 - val_output1_accuracy: 0.5146 - val_output2_mse: 0.0455\n",
      "Epoch 2/20\n",
      "102/102 [==============================] - 3s 32ms/step - loss: 0.9998 - output1_loss: 0.9688 - output2_loss: 0.0309 - output1_accuracy: 0.6171 - output2_mse: 0.0309 - val_loss: 1.2263 - val_output1_loss: 1.1769 - val_output2_loss: 0.0494 - val_output1_accuracy: 0.5389 - val_output2_mse: 0.0494\n",
      "Epoch 3/20\n",
      "102/102 [==============================] - 3s 32ms/step - loss: 0.9698 - output1_loss: 0.9404 - output2_loss: 0.0294 - output1_accuracy: 0.6260 - output2_mse: 0.0294 - val_loss: 1.2353 - val_output1_loss: 1.1943 - val_output2_loss: 0.0410 - val_output1_accuracy: 0.5222 - val_output2_mse: 0.0410\n",
      "Epoch 4/20\n",
      "102/102 [==============================] - 3s 32ms/step - loss: 0.9298 - output1_loss: 0.9027 - output2_loss: 0.0271 - output1_accuracy: 0.6412 - output2_mse: 0.0271 - val_loss: 1.2316 - val_output1_loss: 1.1925 - val_output2_loss: 0.0391 - val_output1_accuracy: 0.5340 - val_output2_mse: 0.0391\n",
      "Epoch 5/20\n",
      "102/102 [==============================] - 3s 32ms/step - loss: 0.8794 - output1_loss: 0.8535 - output2_loss: 0.0259 - output1_accuracy: 0.6632 - output2_mse: 0.0259 - val_loss: 1.1949 - val_output1_loss: 1.1528 - val_output2_loss: 0.0421 - val_output1_accuracy: 0.5660 - val_output2_mse: 0.0421\n",
      "Epoch 6/20\n",
      "102/102 [==============================] - 3s 31ms/step - loss: 0.8502 - output1_loss: 0.8243 - output2_loss: 0.0258 - output1_accuracy: 0.6726 - output2_mse: 0.0258 - val_loss: 1.1920 - val_output1_loss: 1.1445 - val_output2_loss: 0.0475 - val_output1_accuracy: 0.5625 - val_output2_mse: 0.0475\n",
      "Epoch 7/20\n",
      "102/102 [==============================] - 3s 31ms/step - loss: 0.8109 - output1_loss: 0.7876 - output2_loss: 0.0233 - output1_accuracy: 0.6851 - output2_mse: 0.0233 - val_loss: 1.1649 - val_output1_loss: 1.1244 - val_output2_loss: 0.0406 - val_output1_accuracy: 0.5653 - val_output2_mse: 0.0406\n",
      "Epoch 8/20\n",
      "102/102 [==============================] - 3s 32ms/step - loss: 0.7925 - output1_loss: 0.7670 - output2_loss: 0.0255 - output1_accuracy: 0.6948 - output2_mse: 0.0255 - val_loss: 1.2054 - val_output1_loss: 1.1558 - val_output2_loss: 0.0496 - val_output1_accuracy: 0.5604 - val_output2_mse: 0.0496\n",
      "Epoch 9/20\n",
      "102/102 [==============================] - 3s 31ms/step - loss: 0.7598 - output1_loss: 0.7344 - output2_loss: 0.0254 - output1_accuracy: 0.7074 - output2_mse: 0.0254 - val_loss: 1.1309 - val_output1_loss: 1.0893 - val_output2_loss: 0.0415 - val_output1_accuracy: 0.5813 - val_output2_mse: 0.0415\n",
      "Epoch 10/20\n",
      "102/102 [==============================] - 3s 31ms/step - loss: 0.7216 - output1_loss: 0.6995 - output2_loss: 0.0221 - output1_accuracy: 0.7250 - output2_mse: 0.0221 - val_loss: 1.1298 - val_output1_loss: 1.0891 - val_output2_loss: 0.0406 - val_output1_accuracy: 0.5889 - val_output2_mse: 0.0406\n",
      "Epoch 11/20\n",
      "102/102 [==============================] - 3s 31ms/step - loss: 0.6953 - output1_loss: 0.6735 - output2_loss: 0.0218 - output1_accuracy: 0.7298 - output2_mse: 0.0218 - val_loss: 1.1399 - val_output1_loss: 1.0979 - val_output2_loss: 0.0420 - val_output1_accuracy: 0.5889 - val_output2_mse: 0.0420\n",
      "Epoch 12/20\n",
      "102/102 [==============================] - 3s 31ms/step - loss: 0.6819 - output1_loss: 0.6592 - output2_loss: 0.0227 - output1_accuracy: 0.7356 - output2_mse: 0.0227 - val_loss: 1.1415 - val_output1_loss: 1.1028 - val_output2_loss: 0.0387 - val_output1_accuracy: 0.5819 - val_output2_mse: 0.0387\n",
      "Epoch 13/20\n",
      "102/102 [==============================] - 3s 32ms/step - loss: 0.6561 - output1_loss: 0.6360 - output2_loss: 0.0201 - output1_accuracy: 0.7444 - output2_mse: 0.0201 - val_loss: 1.1798 - val_output1_loss: 1.1317 - val_output2_loss: 0.0481 - val_output1_accuracy: 0.6021 - val_output2_mse: 0.0481\n",
      "Epoch 14/20\n",
      "102/102 [==============================] - 3s 32ms/step - loss: 0.6375 - output1_loss: 0.6160 - output2_loss: 0.0216 - output1_accuracy: 0.7602 - output2_mse: 0.0216 - val_loss: 1.1243 - val_output1_loss: 1.0870 - val_output2_loss: 0.0373 - val_output1_accuracy: 0.6021 - val_output2_mse: 0.0373\n",
      "Epoch 15/20\n",
      "102/102 [==============================] - 3s 32ms/step - loss: 0.6112 - output1_loss: 0.5917 - output2_loss: 0.0195 - output1_accuracy: 0.7641 - output2_mse: 0.0195 - val_loss: 1.1035 - val_output1_loss: 1.0654 - val_output2_loss: 0.0381 - val_output1_accuracy: 0.6028 - val_output2_mse: 0.0381\n",
      "Epoch 16/20\n",
      "102/102 [==============================] - 3s 32ms/step - loss: 0.5822 - output1_loss: 0.5631 - output2_loss: 0.0191 - output1_accuracy: 0.7802 - output2_mse: 0.0191 - val_loss: 1.1037 - val_output1_loss: 1.0613 - val_output2_loss: 0.0424 - val_output1_accuracy: 0.6132 - val_output2_mse: 0.0424\n",
      "Epoch 17/20\n",
      "102/102 [==============================] - 3s 32ms/step - loss: 0.5716 - output1_loss: 0.5529 - output2_loss: 0.0188 - output1_accuracy: 0.7855 - output2_mse: 0.0188 - val_loss: 1.1312 - val_output1_loss: 1.0922 - val_output2_loss: 0.0391 - val_output1_accuracy: 0.6187 - val_output2_mse: 0.0391\n",
      "Epoch 18/20\n",
      "102/102 [==============================] - 3s 32ms/step - loss: 0.5409 - output1_loss: 0.5243 - output2_loss: 0.0167 - output1_accuracy: 0.7918 - output2_mse: 0.0167 - val_loss: 1.1443 - val_output1_loss: 1.1078 - val_output2_loss: 0.0365 - val_output1_accuracy: 0.6028 - val_output2_mse: 0.0365\n",
      "Epoch 19/20\n",
      "102/102 [==============================] - 3s 32ms/step - loss: 0.5370 - output1_loss: 0.5173 - output2_loss: 0.0197 - output1_accuracy: 0.7946 - output2_mse: 0.0197 - val_loss: 1.1553 - val_output1_loss: 1.1167 - val_output2_loss: 0.0386 - val_output1_accuracy: 0.5993 - val_output2_mse: 0.0386\n",
      "Epoch 20/20\n",
      "102/102 [==============================] - 3s 32ms/step - loss: 0.5212 - output1_loss: 0.5031 - output2_loss: 0.0181 - output1_accuracy: 0.8020 - output2_mse: 0.0181 - val_loss: 1.2127 - val_output1_loss: 1.1722 - val_output2_loss: 0.0405 - val_output1_accuracy: 0.5875 - val_output2_mse: 0.0405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1628857bf08>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_model.fit(X,[y1,y2], batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee713594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "output1,output2=multihead_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29b4ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1=output1.argmax(axis=1)\n",
    "output2=output2.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c81e5c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=output1+output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a558e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_reg(y_true, y_pred):\n",
    "    d = np.abs(y_true-y_pred)\n",
    "    return (1-(d//6))*(d)+(d//6)*(12-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcb17817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6160935001671315"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_sense_reg(y_test,output).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f08c5f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565701dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e942b61b",
   "metadata": {},
   "source": [
    "Label transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53fc6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ded11d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ya_hour=2*np.pi*(label[:,0]+label[:,1]/60)/12\n",
    "ya_hour1=np.sin(ya_hour)\n",
    "ya_hour2=np.cos(ya_hour)\n",
    "y_l=np.stack((ya_hour1,ya_hour2),axis=1)\n",
    "y_l=np.concatenate((y_l,label),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af649417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (14400, 150, 150)\n",
      "Test set: (3600, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "X, X_test, y, y_test = train_test_split(data, y_l, test_size=0.2, random_state=42)\n",
    "print(f\"Train set: {X.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "y=y[:,:2]\n",
    "y_test=y_test[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f867cfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 148, 148, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 74, 74, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 36, 36, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 18, 18, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 8, 8, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 285,634\n",
      "Trainable params: 285,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformation_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(150,150,1)),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",strides=2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64,activation=\"relu\"),\n",
    "        layers.Dense(2,activation=\"tanh\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transformation_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c231f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "transformation_model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,), metrics=\"mse\", run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "934d643a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "102/102 [==============================] - 4s 42ms/step - loss: 0.5003 - mse: 0.5003 - val_loss: 0.4982 - val_mse: 0.4982\n",
      "Epoch 2/20\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.4314 - mse: 0.4314 - val_loss: 0.3519 - val_mse: 0.3519\n",
      "Epoch 3/20\n",
      "102/102 [==============================] - 4s 40ms/step - loss: 0.2909 - mse: 0.2909 - val_loss: 0.2527 - val_mse: 0.2527\n",
      "Epoch 4/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.2003 - mse: 0.2003 - val_loss: 0.1646 - val_mse: 0.1646\n",
      "Epoch 5/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.1303 - mse: 0.1303 - val_loss: 0.1198 - val_mse: 0.1198\n",
      "Epoch 6/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0883 - mse: 0.0883 - val_loss: 0.0857 - val_mse: 0.0857\n",
      "Epoch 7/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0656 - mse: 0.0656 - val_loss: 0.0724 - val_mse: 0.0724\n",
      "Epoch 8/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0526 - mse: 0.0526 - val_loss: 0.0604 - val_mse: 0.0604\n",
      "Epoch 9/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0565 - val_mse: 0.0565\n",
      "Epoch 10/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0367 - mse: 0.0367 - val_loss: 0.0530 - val_mse: 0.0530\n",
      "Epoch 11/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0455 - val_mse: 0.0455\n",
      "Epoch 12/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0292 - mse: 0.0292 - val_loss: 0.0440 - val_mse: 0.0440\n",
      "Epoch 13/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.0400 - val_mse: 0.0400\n",
      "Epoch 14/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.0410 - val_mse: 0.0410\n",
      "Epoch 15/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0411 - val_mse: 0.0411\n",
      "Epoch 16/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 17/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0371 - val_mse: 0.0371\n",
      "Epoch 18/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0368 - val_mse: 0.0368\n",
      "Epoch 19/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 20/20\n",
      "102/102 [==============================] - 4s 41ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0343 - val_mse: 0.0343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19207bc3188>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformation_model.fit(X,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "00b1aa52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "output=transformation_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1e2804a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1=output[:,0]/np.sqrt(np.square(output[:,0])+np.square(output[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a7793a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2=output[:,1]/np.sqrt(np.square(output[:,0])+np.square(output[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "05e6ba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "angle=[]\n",
    "for i in range(len(predict1)):\n",
    "    a_acos = math.acos(predict2[i])\n",
    "    if predict1[i] < 0:\n",
    "        angle.append( math.degrees(-a_acos) % 360 )\n",
    "    else: \n",
    "        angle.append( math.degrees(a_acos) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a1ebc3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle=np.stack(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "56ed7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_p=12*angle/360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2d02321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test[:,0]+y_test[:,1]/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a0e556f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_reg(y_true, y_pred):\n",
    "    d = np.abs(y_true-y_pred)\n",
    "    return (1-(d//6))*(d)+(d//6)*(12-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9f241feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34466448749401635"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_sense_reg(y_test,time_p).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e28a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66657553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d0fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869da12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932a880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ad5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f0ee446",
   "metadata": {},
   "source": [
    "optimze final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "325627b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8caf828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ya_hour=2*np.pi*(label[:,0]+label[:,1]/60)/12\n",
    "ya_hour1=np.sin(ya_hour)\n",
    "ya_hour2=np.cos(ya_hour)\n",
    "y_l=np.stack((ya_hour1,ya_hour2),axis=1)\n",
    "y_l=np.concatenate((y_l,label),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc0151ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (14400, 150, 150)\n",
      "Test set: (3600, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "X, X_test, y, y_test = train_test_split(data, y_l, test_size=0.2, random_state=42)\n",
    "print(f\"Train set: {X.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "y=y[:,:2]\n",
    "y_test=y_test[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1acdff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test[:,0]+y_test[:,1]/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a839a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 36, 36, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 18, 18, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                262208    \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 64)               3         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 285,637\n",
      "Trainable params: 285,634\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(150,150,1)),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=keras.layers.LeakyReLU(alpha=0.01),strides=1,kernel_regularizer=regularizers.L2(1e-4)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=keras.layers.LeakyReLU(alpha=0.01),strides=2,kernel_regularizer=regularizers.L2(1e-4)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=keras.layers.LeakyReLU(alpha=0.01),strides=1,kernel_regularizer=regularizers.L2(1e-4)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64,activation=keras.layers.LeakyReLU(alpha=0.01),kernel_regularizer=regularizers.L2(1e-4)),\n",
    "        layers.Normalization(axis=None),\n",
    "        layers.Dense(2,activation=\"tanh\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab931888",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "final_model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,), metrics=\"mse\", run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14273066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "102/102 [==============================] - 5s 48ms/step - loss: 0.0492 - mse: 0.0258 - val_loss: 0.0503 - val_mse: 0.0271\n",
      "Epoch 2/20\n",
      "102/102 [==============================] - 5s 45ms/step - loss: 0.0485 - mse: 0.0254 - val_loss: 0.0507 - val_mse: 0.0277\n",
      "Epoch 3/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.0472 - mse: 0.0243 - val_loss: 0.0490 - val_mse: 0.0263\n",
      "Epoch 4/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.0466 - mse: 0.0239 - val_loss: 0.0482 - val_mse: 0.0258\n",
      "Epoch 5/20\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.0462 - mse: 0.0238 - val_loss: 0.0484 - val_mse: 0.0262\n",
      "Epoch 6/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.0456 - mse: 0.0234 - val_loss: 0.0456 - val_mse: 0.0235\n",
      "Epoch 7/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.0448 - mse: 0.0228 - val_loss: 0.0457 - val_mse: 0.0238\n",
      "Epoch 8/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.0441 - mse: 0.0223 - val_loss: 0.0454 - val_mse: 0.0238\n",
      "Epoch 9/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.0432 - mse: 0.0217 - val_loss: 0.0439 - val_mse: 0.0226\n",
      "Epoch 10/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.0419 - mse: 0.0207 - val_loss: 0.0446 - val_mse: 0.0235\n",
      "Epoch 11/20\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.0424 - mse: 0.0214 - val_loss: 0.0475 - val_mse: 0.0265\n",
      "Epoch 12/20\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.0424 - mse: 0.0214 - val_loss: 0.0446 - val_mse: 0.0238\n",
      "Epoch 13/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.0412 - mse: 0.0205 - val_loss: 0.0446 - val_mse: 0.0241\n",
      "Epoch 14/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.0404 - mse: 0.0200 - val_loss: 0.0417 - val_mse: 0.0214\n",
      "Epoch 15/20\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.0403 - mse: 0.0201 - val_loss: 0.0411 - val_mse: 0.0210\n",
      "Epoch 16/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.0398 - mse: 0.0198 - val_loss: 0.0432 - val_mse: 0.0232\n",
      "Epoch 17/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.0403 - mse: 0.0203 - val_loss: 0.0423 - val_mse: 0.0223\n",
      "Epoch 18/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.0395 - mse: 0.0196 - val_loss: 0.0408 - val_mse: 0.0211\n",
      "Epoch 19/20\n",
      "102/102 [==============================] - 5s 45ms/step - loss: 0.0392 - mse: 0.0195 - val_loss: 0.0419 - val_mse: 0.0223\n",
      "Epoch 20/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.0390 - mse: 0.0194 - val_loss: 0.0394 - val_mse: 0.0200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b3255c5b48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb9384c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "output=final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea89ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict1=output[:,0]/np.sqrt(np.square(output[:,0])+np.square(output[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "497cf56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict2=output[:,1]/np.sqrt(np.square(output[:,0])+np.square(output[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fcef2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "angle=[]\n",
    "for i in range(len(predict1)):\n",
    "    a_acos = math.acos(predict2[i])\n",
    "    if predict1[i] < 0:\n",
    "        angle.append( math.degrees(-a_acos) % 360 )\n",
    "    else: \n",
    "        angle.append( math.degrees(a_acos) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a9b5be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "angle=np.stack(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fb2e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_p=12*angle/360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7293e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_p=12*angle/360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8e4e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_reg(y_true, y_pred):\n",
    "    d = np.abs(y_true-y_pred)\n",
    "    return (1-(d//6))*(d)+(d//6)*(12-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "511ea2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24003285385500078"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_sense_reg(y_test,time_p).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ade3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db467e66",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e799b788",
   "metadata": {},
   "source": [
    "## Task 3: Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce0ed8",
   "metadata": {},
   "source": [
    "In this task, we use MNIST dataset to train the generative models and obtain new figures. We directly call the Tensorflow API to download the dataset. However, the original dataset is also available on this website: <https://deepai.org/dataset/mnist>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f73dea-fe2c-449b-ad2d-ab390c1e07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Conv2DTranspose, Reshape, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc67c38-8af6-4fbf-9d25-bfe3316fd40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocessing\n",
    "X = np.concatenate((x_train, x_test), axis=0)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(X)\n",
    "X = X.astype(\"float32\") / 255.\n",
    "X = X.reshape(X.shape + (1,))\n",
    "print(f\"The shape of dataset: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe542e-7c75-4853-aac1-8a17a1f1f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use modified grid_plot functions in the tutorial           \n",
    "def grid_plot(images, epoch=\"\", name=\"\", n=3, save=False, scale=False):\n",
    "    if scale:\n",
    "        images = (images + 1) / 2.0\n",
    "    for index in range(n * n):\n",
    "        plt.subplot(n, n, 1 + index)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[index])\n",
    "    fig = plt.gcf()\n",
    "    fig.suptitle(name + '  '+ str(epoch), fontsize=14)\n",
    "    if save:\n",
    "        filename = 'results/generated_plot_e%03d_f.png' % (epoch+1)\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8536d-b0f7-4d8b-8caf-ce7b7839590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "grid_plot(X[np.random.randint(0, 1000, 9)], name=\"MNIST dataset (28 X 28 X 1)\", n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87954b3-74ed-4ea5-ab1a-68b3f311fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use modified build_conv_net and build_deconv_net functions in the tutorial\n",
    "def build_conv_net(in_shape, out_shape, out_activation='sigmoid'):\n",
    "    \"\"\"\n",
    "    Build a basic convolutional network\n",
    "    \"\"\"\n",
    "    in_put = Input(shape=in_shape)\n",
    "    \n",
    "    x = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(in_put)\n",
    "    x = Conv2D(kernel_size=3, filters=64, padding='same', activation='relu', strides=(2,2))(x)\n",
    "    x = Conv2D(kernel_size=3, filters=64, padding='same', activation='relu')(x)\n",
    "    x = Conv2D(kernel_size=3, filters=64, padding='same', activation='relu')(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(out_shape, activation=out_activation)(x)\n",
    "    model = tf.keras.Model(in_put, x)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_deconv_net(latent_dim, activation_out='sigmoid'):\n",
    "    \"\"\"\n",
    "    Build a deconvolutional network for decoding/upscaling latent vectors\n",
    "\n",
    "    When building the deconvolutional architecture, usually it is best to use the same layer sizes that \n",
    "    were used in the downsampling network and the Conv2DTranspose layers are used instead of Conv2D layers. \n",
    "    Using identical layers and hyperparameters ensures that the dimensionality of our output matches the\n",
    "    shape of our input images. \n",
    "    \"\"\"\n",
    "    in_put = Input(shape=latent_dim)\n",
    "    x = Dense(14 * 14 * 64)(in_put)\n",
    "    x = Reshape((14, 14, 64))(x) # This matches the output size of the downsampling architecture\n",
    "    x = Conv2DTranspose(32, 3, padding='same', activation='relu', strides=(2,2))(x)\n",
    "    x = Conv2D(filters=1, kernel_size=3, activation=activation_out, padding='same')(x)\n",
    "    model = tf.keras.Model(in_put, x)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f2366",
   "metadata": {},
   "source": [
    "### Convolutional Autoencoder (CAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1be4c8-6459-449c-b197-9d6eee8d35f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAE\n",
    "# Use the build_convolutional_autoencoder function in the tutorial\n",
    "def build_convolutional_autoencoder(data_shape, latent_dim):\n",
    "    encoder = build_conv_net(in_shape=data_shape, out_shape=latent_dim)\n",
    "    decoder = build_deconv_net(latent_dim, activation_out='sigmoid')\n",
    "    autoencoder = tf.keras.Sequential([encoder, decoder])\n",
    "    autoencoder.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return autoencoder\n",
    "\n",
    "# Defining the model dimensions and building it\n",
    "image_size = X.shape[1:]\n",
    "latent_dim = 32\n",
    "num_filters = 64\n",
    "cae = build_convolutional_autoencoder(image_size, latent_dim)\n",
    "\n",
    "for epoch in range(0, 11):\n",
    "    cae.fit(x=X, y=X, epochs=1, batch_size=64, verbose=0)\n",
    "    print('\\nEpoch: ', epoch)\n",
    "    samples = X[:9]\n",
    "    reconstructed = cae.predict(samples, verbose=0)\n",
    "    grid_plot(samples, epoch, name='Original', n=3, save=False)\n",
    "    grid_plot(reconstructed, epoch, name='Reconstructed', n=3, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031b7b6",
   "metadata": {},
   "source": [
    "### Variational Autoencoders (VAEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97220a0e-6eaa-42fb-b193-8ddf41e54e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Sampling class and the build_vae function in the tutorial\n",
    "class Sampling(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Custom layer for the variational autoencoder\n",
    "    It takes two vectors as input - one for means and other for variances of the latent variables described by a multimodal gaussian\n",
    "    Its output is a latent vector randomly sampled from this distribution\n",
    "    \"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_var) * epsilon\n",
    "\n",
    "    \n",
    "def build_vae(data_shape, latent_dim, filters=128):\n",
    "\n",
    "    # Building the encoder - starts with a simple downsampling convolutional network  \n",
    "    encoder = build_conv_net(data_shape, latent_dim*2)\n",
    "    \n",
    "    # Adding special sampling layer that uses the reparametrization trick \n",
    "    z_mean = Dense(latent_dim)(encoder.output)\n",
    "    z_var = Dense(latent_dim)(encoder.output)\n",
    "    z = Sampling()([z_mean, z_var])\n",
    "    \n",
    "    # Connecting the two encoder parts\n",
    "    encoder = tf.keras.Model(inputs=encoder.input, outputs=z)\n",
    "\n",
    "    # Defining the decoder which is a regular upsampling deconvolutional network\n",
    "    decoder = build_deconv_net(latent_dim, activation_out='sigmoid')\n",
    "    vae = tf.keras.Model(inputs=encoder.input, outputs=decoder(z))\n",
    "    \n",
    "    # Adding the special loss term\n",
    "    kl_loss = -0.5 * tf.reduce_sum(z_var - tf.square(z_mean) - tf.exp(z_var) + 1)\n",
    "    vae.add_loss(kl_loss/tf.cast(tf.keras.backend.prod(data_shape), tf.float32))\n",
    "\n",
    "    vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='binary_crossentropy')\n",
    "\n",
    "    return encoder, decoder, vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bf4331-e975-42bb-8c0c-fff00d26daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the VAE model\n",
    "latent_dim = 32\n",
    "encoder, decoder, vae = build_vae(X.shape[1:], latent_dim)\n",
    "\n",
    "# Generate random vectors that we will use to sample our latent space\n",
    "for epoch in range(0, 20):\n",
    "    vae.fit(x=X, y=X, epochs=1, batch_size=16, verbose=1)\n",
    "    latent_vectors = np.random.randn(9, latent_dim)\n",
    "    images = decoder(latent_vectors)\n",
    "    grid_plot(images, epoch, name='VAE generated images (randomly sampled from the latent space)', n=3, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bcad48-d2ae-42a2-8860-2ce28bb8915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 32\n",
    "for i in range(-2, 3):\n",
    "    np.random.seed(42)\n",
    "    latent_vectors = np.tile(np.random.randn(latent_dim), (7, 1))\n",
    "    latent_vectors[:, 9] = np.linspace(-5, 5, num=7)\n",
    "    latent_vectors[:, 26] = i * np.ones(7)\n",
    "\n",
    "    images = decoder(latent_vectors)\n",
    "    plt.figure(figsize = (15, 1.5))\n",
    "    for index in range(7):\n",
    "        plt.subplot(1, 7, index + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[index], aspect='auto')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8570e5ac",
   "metadata": {},
   "source": [
    "### Generative Adversarial Networks (GANs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a1a70-11b7-4fc3-a2fa-8509594f953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use build_gan, run_generator, get_batch, train_gan function in the tutorial\n",
    "def build_gan(data_shape, latent_dim, lr=0.0002, beta_1=0.5):\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=lr, beta_1=beta_1)\n",
    "\n",
    "    # Usually the GAN generator has tanh activation function in the output layer\n",
    "    generator = build_deconv_net(latent_dim, activation_out='tanh')\n",
    "    \n",
    "    # Build and compile the discriminator\n",
    "    discriminator = build_conv_net(in_shape=data_shape, out_shape=1) # Single output for binary classification\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    # End-to-end GAN model for training the generator\n",
    "    discriminator.trainable = False\n",
    "    true_fake_prediction = discriminator(generator.output)\n",
    "    GAN = tf.keras.Model(inputs=generator.input, outputs=true_fake_prediction)\n",
    "    GAN = tf.keras.models.Sequential([generator, discriminator])\n",
    "    GAN.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    return discriminator, generator, GAN\n",
    "\n",
    "\n",
    "def run_generator(generator, n_samples=100):\n",
    "    \"\"\"\n",
    "    Run the generator model and generate n samples of synthetic images using random latent vectors\n",
    "    \"\"\"\n",
    "    latent_dim = generator.layers[0].input_shape[-1]\n",
    "    generator_input = np.random.randn(n_samples, latent_dim[1])\n",
    "\n",
    "    return generator.predict(generator_input)\n",
    "    \n",
    "\n",
    "def get_batch(generator, dataset, batch_size=64):\n",
    "    \"\"\"\n",
    "    Gets a single batch of samples (X) and labels (y) for the training the discriminator.\n",
    "    One half from the real dataset (labeled as 1s), the other created by the generator model (labeled as 0s).\n",
    "    \"\"\"\n",
    "    batch_size //= 2 # Split evenly among fake and real samples\n",
    "\n",
    "    fake_data = run_generator(generator, n_samples=batch_size)\n",
    "    real_data = dataset[np.random.randint(0, dataset.shape[0], batch_size)]\n",
    "\n",
    "    X = np.concatenate([fake_data, real_data], axis=0)\n",
    "    y = np.concatenate([np.zeros([batch_size, 1]), np.ones([batch_size, 1])], axis=0)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def train_gan(generator, discriminator, gan, dataset, latent_dim, n_epochs=20, batch_size=64):\n",
    "\n",
    "    batches_per_epoch = int(dataset.shape[0] / batch_size / 2)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in range(batches_per_epoch):\n",
    "            \n",
    "            # 1) Train discriminator both on real and synthesized images\n",
    "            X, y = get_batch(generator, dataset, batch_size=batch_size)\n",
    "            discriminator_loss = discriminator.train_on_batch(X, y)\n",
    "\n",
    "            # 2) Train generator (note that now the label of synthetic images is reversed to 1)\n",
    "            X_gan = np.random.randn(batch_size, latent_dim)\n",
    "            y_gan = np.ones([batch_size, 1])\n",
    "            generator_loss = gan.train_on_batch(X_gan, y_gan)\n",
    "            \n",
    "        noise = np.random.randn(16, latent_dim)\n",
    "        images = generator.predict(noise)\n",
    "        grid_plot(images, epoch, name='GAN generated images', n=3, save=False, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f0309-dae4-42cf-8dc1-1692f34dd6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train the model (need around 10 epochs to start seeing some results)\n",
    "latent_dim = 256\n",
    "discriminator, generator, gan = build_gan(X.shape[1:], latent_dim)\n",
    "\n",
    "train_gan(generator, discriminator, gan, X, latent_dim, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110af65a-1881-49c8-a765-b6f960e7ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "\n",
    "np.random.seed(13)\n",
    "latent_vectors = np.tile(np.random.randn(latent_dim), (7, 1))\n",
    "latent_vectors[:, 0] = np.linspace(-30, 30, num=7)\n",
    "\n",
    "images = generator(latent_vectors)\n",
    "plt.figure(figsize = (15, 1.5))\n",
    "for index in range(7):\n",
    "    plt.subplot(1, 7, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index], aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170806b-223f-4ab8-978f-b271171f51c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "\n",
    "np.random.seed(13)\n",
    "latent_vectors = np.tile(np.random.randn(latent_dim), (7, 1))\n",
    "latent_vectors[:, 119] = np.linspace(-30, 30, num=7)\n",
    "\n",
    "images = generator(latent_vectors)\n",
    "plt.figure(figsize = (15, 1.5))\n",
    "for index in range(7):\n",
    "    plt.subplot(1, 7, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index], aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce67ad6-604c-428b-bfd7-c17a7e35968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "\n",
    "np.random.seed(13)\n",
    "latent_vectors = np.tile(np.random.randn(latent_dim), (7, 1))\n",
    "latent_vectors[:, 125] = np.linspace(0, 30, num=7)\n",
    "\n",
    "images = generator(latent_vectors)\n",
    "plt.figure(figsize = (15, 1.5))\n",
    "for index in range(7):\n",
    "    plt.subplot(1, 7, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index], aspect='auto')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
