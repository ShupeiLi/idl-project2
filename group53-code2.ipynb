{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1614d13",
   "metadata": {},
   "source": [
    "# Assignment 2: Building MLPs, CNNs, and Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2fa644",
   "metadata": {},
   "source": [
    "## Task 1: Learn the basics of Keras API for Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006843a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92b98f73",
   "metadata": {},
   "source": [
    "## Task 2: Develop a \"Tell-the-time\" network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2755afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19402e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47eb7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"./a2_data/images.npy\")\n",
    "label = np.load(\"./a2_data/labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf715a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data/255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54da8c83",
   "metadata": {},
   "source": [
    "Regression Task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "435c5ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_r=label[:,0]+label[:,1]/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b88be9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_reg(y_true, y_pred):\n",
    "    d = K.abs(y_true-y_pred)\n",
    "    return (1-(d//6))*(d)+(d//6)*(12-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4bb78af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (14400, 150, 150)\n",
      "Test set: (3600, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "X, X_test, y, y_test = train_test_split(data, label_r, test_size=0.2, random_state=42)\n",
    "print(f\"Train set: {X.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a7c68db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 148, 148, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 36, 36, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 18, 18, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 8, 8, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,929\n",
      "Trainable params: 72,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "regression_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(150,150,1)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\",strides=2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64,activation=\"relu\"),\n",
    "        layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "regression_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "830ef99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 60\n",
    "regression_model.compile(loss=\"mse\", optimizer=\"adam\", metrics=common_sense_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28a0ef9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "203/203 [==============================] - 5s 19ms/step - loss: 13.7863 - common_sense_reg: 3.0049 - val_loss: 12.3277 - val_common_sense_reg: 3.0180\n",
      "Epoch 2/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 12.1149 - common_sense_reg: 2.9987 - val_loss: 11.9883 - val_common_sense_reg: 2.9832\n",
      "Epoch 3/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 11.7883 - common_sense_reg: 2.9071 - val_loss: 10.9861 - val_common_sense_reg: 2.7747\n",
      "Epoch 4/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 10.5699 - common_sense_reg: 2.6683 - val_loss: 10.0905 - val_common_sense_reg: 2.5747\n",
      "Epoch 5/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 9.7920 - common_sense_reg: 2.4883 - val_loss: 9.7146 - val_common_sense_reg: 2.4516\n",
      "Epoch 6/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 9.4181 - common_sense_reg: 2.4291 - val_loss: 9.0243 - val_common_sense_reg: 2.3464\n",
      "Epoch 7/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 9.0144 - common_sense_reg: 2.3614 - val_loss: 9.6056 - val_common_sense_reg: 2.3529\n",
      "Epoch 8/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 8.7500 - common_sense_reg: 2.3121 - val_loss: 8.4847 - val_common_sense_reg: 2.2380\n",
      "Epoch 9/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 8.5698 - common_sense_reg: 2.2728 - val_loss: 8.4630 - val_common_sense_reg: 2.2552\n",
      "Epoch 10/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 8.0889 - common_sense_reg: 2.2088 - val_loss: 8.2268 - val_common_sense_reg: 2.1907\n",
      "Epoch 11/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 7.9243 - common_sense_reg: 2.1727 - val_loss: 8.0989 - val_common_sense_reg: 2.1804\n",
      "Epoch 12/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 7.4923 - common_sense_reg: 2.1144 - val_loss: 7.5364 - val_common_sense_reg: 2.0734\n",
      "Epoch 13/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 7.1705 - common_sense_reg: 2.0634 - val_loss: 7.4696 - val_common_sense_reg: 2.0487\n",
      "Epoch 14/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 7.0835 - common_sense_reg: 2.0419 - val_loss: 7.3953 - val_common_sense_reg: 2.0650\n",
      "Epoch 15/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 6.7778 - common_sense_reg: 1.9916 - val_loss: 7.5930 - val_common_sense_reg: 1.9991\n",
      "Epoch 16/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 6.5732 - common_sense_reg: 1.9511 - val_loss: 6.8020 - val_common_sense_reg: 1.9470\n",
      "Epoch 17/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 6.4959 - common_sense_reg: 1.9397 - val_loss: 6.9262 - val_common_sense_reg: 1.9954\n",
      "Epoch 18/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 6.2614 - common_sense_reg: 1.9054 - val_loss: 6.7320 - val_common_sense_reg: 1.9413\n",
      "Epoch 19/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 6.1197 - common_sense_reg: 1.8743 - val_loss: 6.4548 - val_common_sense_reg: 1.8784\n",
      "Epoch 20/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 5.9078 - common_sense_reg: 1.8363 - val_loss: 6.6098 - val_common_sense_reg: 1.9125\n",
      "Epoch 21/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 5.8219 - common_sense_reg: 1.8244 - val_loss: 6.5772 - val_common_sense_reg: 1.9010\n",
      "Epoch 22/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 5.6321 - common_sense_reg: 1.7848 - val_loss: 6.2357 - val_common_sense_reg: 1.8392\n",
      "Epoch 23/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 5.5562 - common_sense_reg: 1.7721 - val_loss: 6.1607 - val_common_sense_reg: 1.8290\n",
      "Epoch 24/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 5.3090 - common_sense_reg: 1.7265 - val_loss: 5.7778 - val_common_sense_reg: 1.7757\n",
      "Epoch 25/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 5.2219 - common_sense_reg: 1.7073 - val_loss: 5.9621 - val_common_sense_reg: 1.7666\n",
      "Epoch 26/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 5.0756 - common_sense_reg: 1.6811 - val_loss: 5.7179 - val_common_sense_reg: 1.7640\n",
      "Epoch 27/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 4.9130 - common_sense_reg: 1.6443 - val_loss: 5.5041 - val_common_sense_reg: 1.7239\n",
      "Epoch 28/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 4.7759 - common_sense_reg: 1.6271 - val_loss: 5.7314 - val_common_sense_reg: 1.7856\n",
      "Epoch 29/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 4.5846 - common_sense_reg: 1.5884 - val_loss: 5.3670 - val_common_sense_reg: 1.6894\n",
      "Epoch 30/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 4.6013 - common_sense_reg: 1.6013 - val_loss: 5.3817 - val_common_sense_reg: 1.7087\n",
      "Epoch 31/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 4.2795 - common_sense_reg: 1.5291 - val_loss: 5.0083 - val_common_sense_reg: 1.6231\n",
      "Epoch 32/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 4.1870 - common_sense_reg: 1.5129 - val_loss: 5.1330 - val_common_sense_reg: 1.6849\n",
      "Epoch 33/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 4.0032 - common_sense_reg: 1.4755 - val_loss: 4.7737 - val_common_sense_reg: 1.5710\n",
      "Epoch 34/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 3.8810 - common_sense_reg: 1.4503 - val_loss: 4.7189 - val_common_sense_reg: 1.5583\n",
      "Epoch 35/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 3.7998 - common_sense_reg: 1.4379 - val_loss: 4.7455 - val_common_sense_reg: 1.5844\n",
      "Epoch 36/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 3.7042 - common_sense_reg: 1.4191 - val_loss: 4.5748 - val_common_sense_reg: 1.5480\n",
      "Epoch 37/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 3.5263 - common_sense_reg: 1.3848 - val_loss: 4.4443 - val_common_sense_reg: 1.5284\n",
      "Epoch 38/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 3.4078 - common_sense_reg: 1.3640 - val_loss: 4.4775 - val_common_sense_reg: 1.5379\n",
      "Epoch 39/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 3.2634 - common_sense_reg: 1.3358 - val_loss: 4.4530 - val_common_sense_reg: 1.5223\n",
      "Epoch 40/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 3.2001 - common_sense_reg: 1.3229 - val_loss: 4.3054 - val_common_sense_reg: 1.4991\n",
      "Epoch 41/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 3.0849 - common_sense_reg: 1.3021 - val_loss: 4.2173 - val_common_sense_reg: 1.4754\n",
      "Epoch 42/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 3.0017 - common_sense_reg: 1.2842 - val_loss: 4.4353 - val_common_sense_reg: 1.5208\n",
      "Epoch 43/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.9005 - common_sense_reg: 1.2599 - val_loss: 4.3019 - val_common_sense_reg: 1.4990\n",
      "Epoch 44/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.8110 - common_sense_reg: 1.2444 - val_loss: 3.9225 - val_common_sense_reg: 1.4243\n",
      "Epoch 45/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.6986 - common_sense_reg: 1.2196 - val_loss: 3.9701 - val_common_sense_reg: 1.4359\n",
      "Epoch 46/60\n",
      "203/203 [==============================] - 3s 17ms/step - loss: 2.7321 - common_sense_reg: 1.2305 - val_loss: 4.3264 - val_common_sense_reg: 1.4446\n",
      "Epoch 47/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.5895 - common_sense_reg: 1.1927 - val_loss: 3.8724 - val_common_sense_reg: 1.4190\n",
      "Epoch 48/60\n",
      "203/203 [==============================] - 3s 17ms/step - loss: 2.5227 - common_sense_reg: 1.1853 - val_loss: 4.1372 - val_common_sense_reg: 1.4520\n",
      "Epoch 49/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.5726 - common_sense_reg: 1.1973 - val_loss: 4.3031 - val_common_sense_reg: 1.4915\n",
      "Epoch 50/60\n",
      "203/203 [==============================] - 3s 17ms/step - loss: 2.4372 - common_sense_reg: 1.1658 - val_loss: 3.8232 - val_common_sense_reg: 1.3944\n",
      "Epoch 51/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.3150 - common_sense_reg: 1.1316 - val_loss: 3.9273 - val_common_sense_reg: 1.4203\n",
      "Epoch 52/60\n",
      "203/203 [==============================] - 3s 17ms/step - loss: 2.3149 - common_sense_reg: 1.1374 - val_loss: 3.8043 - val_common_sense_reg: 1.3862\n",
      "Epoch 53/60\n",
      "203/203 [==============================] - 3s 17ms/step - loss: 2.2854 - common_sense_reg: 1.1304 - val_loss: 3.7854 - val_common_sense_reg: 1.3870\n",
      "Epoch 54/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.1554 - common_sense_reg: 1.0917 - val_loss: 3.7583 - val_common_sense_reg: 1.3787\n",
      "Epoch 55/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.1889 - common_sense_reg: 1.1047 - val_loss: 3.7220 - val_common_sense_reg: 1.3808\n",
      "Epoch 56/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.0805 - common_sense_reg: 1.0757 - val_loss: 4.0564 - val_common_sense_reg: 1.4118\n",
      "Epoch 57/60\n",
      "203/203 [==============================] - 4s 17ms/step - loss: 2.0102 - common_sense_reg: 1.0596 - val_loss: 3.7741 - val_common_sense_reg: 1.3983\n",
      "Epoch 58/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 2.0394 - common_sense_reg: 1.0723 - val_loss: 3.7180 - val_common_sense_reg: 1.3774\n",
      "Epoch 59/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 1.9311 - common_sense_reg: 1.0445 - val_loss: 3.7679 - val_common_sense_reg: 1.4081\n",
      "Epoch 60/60\n",
      "203/203 [==============================] - 4s 18ms/step - loss: 1.9467 - common_sense_reg: 1.0470 - val_loss: 3.9400 - val_common_sense_reg: 1.4054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18256585b48>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.fit(X,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40b8237b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 4ms/step - loss: 4.0751 - common_sense_reg: 1.4781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.0750956535339355, 1.4780513048171997]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f401f7",
   "metadata": {},
   "source": [
    "Classfication Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7fda48",
   "metadata": {},
   "source": [
    "24 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faf7d8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c71c7128",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c=[]\n",
    "for i in range(24):\n",
    "    la=np.zeros(24)\n",
    "    la[i]=la[i]+1\n",
    "    for j in range(750):\n",
    "        y_c.append(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b7fc567",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c=np.stack(y_c)\n",
    "y_c=np.array(y_c,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f687d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 24)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80eb2d9",
   "metadata": {},
   "source": [
    "def common_sense_cla(y_true, y_pred):\n",
    "    y_true = y_true.numpy().reshape(-1,)\n",
    "    y_pred = y_pred.numpy()\n",
    "    y_pred = y_pred.argmax(axis=1)\n",
    "    d = np.abs(y_true-y_pred)\n",
    "    return 0.5*((1-(d//12))*(d)+(d//12)*(24-d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e8c90c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_cla(y_true, y_pred):\n",
    "    d = K.abs(K.argmax(y_true, axis=1) - K.argmax(y_pred, axis=1))\n",
    "    d = tf.cast(d, tf.float32)\n",
    "    return 0.5 * ((1 - (d // 12)) * (d) + (d // 12) * (24 - d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37e72d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (14400, 150, 150)\n",
      "Test set: (3600, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "X, X_test, y, y_test = train_test_split(data, y_c, test_size=0.2, random_state=42)\n",
    "print(f\"Train set: {X.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "148b9d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 148, 148, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 74, 74, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 36, 36, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 18, 18, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 24)                1560      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287,064\n",
      "Trainable params: 287,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(150,150,1)),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",strides=2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64,activation=keras.layers.LeakyReLU(alpha=0.01)),\n",
    "        layers.Dense(24,activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2920fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 40\n",
    "classification_model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,), metrics=[\"accuracy\",common_sense_cla], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b146d1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "102/102 [==============================] - 5s 46ms/step - loss: 3.1791 - accuracy: 0.0402 - common_sense_cla: 3.0238 - val_loss: 3.1787 - val_accuracy: 0.0333 - val_common_sense_cla: 3.0472\n",
      "Epoch 2/40\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 3.1782 - accuracy: 0.0389 - common_sense_cla: 2.9904 - val_loss: 3.1785 - val_accuracy: 0.0444 - val_common_sense_cla: 3.0687\n",
      "Epoch 3/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 3.1696 - accuracy: 0.0454 - common_sense_cla: 2.9644 - val_loss: 3.1186 - val_accuracy: 0.0681 - val_common_sense_cla: 2.6760\n",
      "Epoch 4/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 2.8926 - accuracy: 0.1087 - common_sense_cla: 2.3547 - val_loss: 2.6603 - val_accuracy: 0.1417 - val_common_sense_cla: 2.0260\n",
      "Epoch 5/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 2.4555 - accuracy: 0.1973 - common_sense_cla: 1.9017 - val_loss: 2.3536 - val_accuracy: 0.2208 - val_common_sense_cla: 1.8125\n",
      "Epoch 6/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 2.1484 - accuracy: 0.2819 - common_sense_cla: 1.6188 - val_loss: 2.1468 - val_accuracy: 0.2826 - val_common_sense_cla: 1.5830\n",
      "Epoch 7/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 1.9114 - accuracy: 0.3607 - common_sense_cla: 1.3832 - val_loss: 1.9564 - val_accuracy: 0.3264 - val_common_sense_cla: 1.4115\n",
      "Epoch 8/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 1.6996 - accuracy: 0.4248 - common_sense_cla: 1.1733 - val_loss: 1.8075 - val_accuracy: 0.3840 - val_common_sense_cla: 1.2406\n",
      "Epoch 9/40\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 1.5067 - accuracy: 0.4863 - common_sense_cla: 0.9965 - val_loss: 1.7527 - val_accuracy: 0.3944 - val_common_sense_cla: 1.1840\n",
      "Epoch 10/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 1.3507 - accuracy: 0.5363 - common_sense_cla: 0.8618 - val_loss: 1.6019 - val_accuracy: 0.4549 - val_common_sense_cla: 1.0115\n",
      "Epoch 11/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 1.1822 - accuracy: 0.5914 - common_sense_cla: 0.7425 - val_loss: 1.5657 - val_accuracy: 0.4743 - val_common_sense_cla: 0.9267\n",
      "Epoch 12/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 1.0498 - accuracy: 0.6343 - common_sense_cla: 0.6318 - val_loss: 1.4573 - val_accuracy: 0.5222 - val_common_sense_cla: 0.8413\n",
      "Epoch 13/40\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.9252 - accuracy: 0.6796 - common_sense_cla: 0.5431 - val_loss: 1.4539 - val_accuracy: 0.5188 - val_common_sense_cla: 0.8590\n",
      "Epoch 14/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.8229 - accuracy: 0.7095 - common_sense_cla: 0.4852 - val_loss: 1.4305 - val_accuracy: 0.5549 - val_common_sense_cla: 0.7608\n",
      "Epoch 15/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.7406 - accuracy: 0.7370 - common_sense_cla: 0.4223 - val_loss: 1.4238 - val_accuracy: 0.5507 - val_common_sense_cla: 0.7458\n",
      "Epoch 16/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.6481 - accuracy: 0.7728 - common_sense_cla: 0.3645 - val_loss: 1.3819 - val_accuracy: 0.5639 - val_common_sense_cla: 0.6799\n",
      "Epoch 17/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.5857 - accuracy: 0.7921 - common_sense_cla: 0.3273 - val_loss: 1.3931 - val_accuracy: 0.5653 - val_common_sense_cla: 0.6809\n",
      "Epoch 18/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.4988 - accuracy: 0.8200 - common_sense_cla: 0.2657 - val_loss: 1.3608 - val_accuracy: 0.5896 - val_common_sense_cla: 0.6816\n",
      "Epoch 19/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.4378 - accuracy: 0.8481 - common_sense_cla: 0.2253 - val_loss: 1.3405 - val_accuracy: 0.6139 - val_common_sense_cla: 0.6201\n",
      "Epoch 20/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.3959 - accuracy: 0.8570 - common_sense_cla: 0.2112 - val_loss: 1.4332 - val_accuracy: 0.5938 - val_common_sense_cla: 0.6389\n",
      "Epoch 21/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.3673 - accuracy: 0.8691 - common_sense_cla: 0.1877 - val_loss: 1.3811 - val_accuracy: 0.6313 - val_common_sense_cla: 0.5747\n",
      "Epoch 22/40\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.3272 - accuracy: 0.8836 - common_sense_cla: 0.1629 - val_loss: 1.4347 - val_accuracy: 0.6451 - val_common_sense_cla: 0.5601\n",
      "Epoch 23/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.2935 - accuracy: 0.8966 - common_sense_cla: 0.1462 - val_loss: 1.4724 - val_accuracy: 0.6389 - val_common_sense_cla: 0.5896\n",
      "Epoch 24/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.2710 - accuracy: 0.9042 - common_sense_cla: 0.1339 - val_loss: 1.5140 - val_accuracy: 0.6403 - val_common_sense_cla: 0.5840\n",
      "Epoch 25/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.2270 - accuracy: 0.9223 - common_sense_cla: 0.1030 - val_loss: 1.5742 - val_accuracy: 0.6458 - val_common_sense_cla: 0.5642\n",
      "Epoch 26/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.2230 - accuracy: 0.9250 - common_sense_cla: 0.1009 - val_loss: 1.6370 - val_accuracy: 0.6451 - val_common_sense_cla: 0.5983\n",
      "Epoch 27/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.2217 - accuracy: 0.9230 - common_sense_cla: 0.1063 - val_loss: 1.5498 - val_accuracy: 0.6528 - val_common_sense_cla: 0.5618\n",
      "Epoch 28/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.1866 - accuracy: 0.9385 - common_sense_cla: 0.0827 - val_loss: 1.5735 - val_accuracy: 0.6549 - val_common_sense_cla: 0.5309\n",
      "Epoch 29/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.1708 - accuracy: 0.9434 - common_sense_cla: 0.0720 - val_loss: 1.6313 - val_accuracy: 0.6597 - val_common_sense_cla: 0.5392\n",
      "Epoch 30/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.1833 - accuracy: 0.9401 - common_sense_cla: 0.0766 - val_loss: 1.7567 - val_accuracy: 0.6451 - val_common_sense_cla: 0.5594\n",
      "Epoch 31/40\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.1463 - accuracy: 0.9513 - common_sense_cla: 0.0649 - val_loss: 1.7209 - val_accuracy: 0.6653 - val_common_sense_cla: 0.5479\n",
      "Epoch 32/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.1202 - accuracy: 0.9628 - common_sense_cla: 0.0467 - val_loss: 1.7895 - val_accuracy: 0.6542 - val_common_sense_cla: 0.5608\n",
      "Epoch 33/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.1212 - accuracy: 0.9623 - common_sense_cla: 0.0511 - val_loss: 1.7679 - val_accuracy: 0.6576 - val_common_sense_cla: 0.5181\n",
      "Epoch 34/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.1125 - accuracy: 0.9671 - common_sense_cla: 0.0442 - val_loss: 1.9871 - val_accuracy: 0.6458 - val_common_sense_cla: 0.5521\n",
      "Epoch 35/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.1267 - accuracy: 0.9600 - common_sense_cla: 0.0520 - val_loss: 2.1536 - val_accuracy: 0.6271 - val_common_sense_cla: 0.5837\n",
      "Epoch 36/40\n",
      "102/102 [==============================] - 5s 45ms/step - loss: 0.1595 - accuracy: 0.9471 - common_sense_cla: 0.0739 - val_loss: 2.0044 - val_accuracy: 0.6514 - val_common_sense_cla: 0.5813\n",
      "Epoch 37/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.1203 - accuracy: 0.9627 - common_sense_cla: 0.0488 - val_loss: 1.9326 - val_accuracy: 0.6535 - val_common_sense_cla: 0.5326\n",
      "Epoch 38/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.1193 - accuracy: 0.9635 - common_sense_cla: 0.0483 - val_loss: 1.8399 - val_accuracy: 0.6611 - val_common_sense_cla: 0.5219\n",
      "Epoch 39/40\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.0847 - accuracy: 0.9774 - common_sense_cla: 0.0286 - val_loss: 1.9754 - val_accuracy: 0.6611 - val_common_sense_cla: 0.5326\n",
      "Epoch 40/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.0690 - accuracy: 0.9816 - common_sense_cla: 0.0246 - val_loss: 1.9266 - val_accuracy: 0.6826 - val_common_sense_cla: 0.5031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24d34d45508>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.fit(X,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48a347ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 11ms/step - loss: 1.9283 - accuracy: 0.6747 - common_sense_cla: 0.5114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9283486604690552, 0.6747221946716309, 0.511388897895813]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f40a74b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f1b009e",
   "metadata": {},
   "source": [
    "72 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e786e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "546d5066",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c=[]\n",
    "for i in range(72):\n",
    "    la=np.zeros(72)\n",
    "    la[i]=la[i]+1\n",
    "    for j in range(250):\n",
    "        y_c.append(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2893096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c=np.stack(y_c)\n",
    "y_c=np.array(y_c,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4e43e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 72)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f090e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_cla(y_true, y_pred):\n",
    "    d = K.abs(K.argmax(y_true, axis=1) - K.argmax(y_pred, axis=1))\n",
    "    d = tf.cast(d, tf.float32)\n",
    "    return 0.5 * ((1 - (d // 36)) * (d) + (d // 36) * (72 - d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6d6d9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (14400, 150, 150)\n",
      "Test set: (3600, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "X, X_test, y, y_test = train_test_split(data, y_c, test_size=0.2, random_state=42)\n",
    "print(f\"Train set: {X.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "326400d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 148, 148, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 74, 74, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 36, 36, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 18, 18, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 72)                4680      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 290,184\n",
      "Trainable params: 290,184\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(150,150,1)),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",strides=2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64,activation=keras.layers.LeakyReLU(alpha=0.01)),\n",
    "        layers.Dense(72,activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddecadfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 40\n",
    "classification_model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,), metrics=[\"accuracy\",common_sense_cla], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b510270d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "102/102 [==============================] - 5s 48ms/step - loss: 4.2780 - accuracy: 0.0116 - common_sense_cla: 8.9613 - val_loss: 4.2771 - val_accuracy: 0.0104 - val_common_sense_cla: 9.0573\n",
      "Epoch 2/40\n",
      "102/102 [==============================] - 5s 45ms/step - loss: 4.2768 - accuracy: 0.0146 - common_sense_cla: 8.9604 - val_loss: 4.2775 - val_accuracy: 0.0090 - val_common_sense_cla: 9.0656\n",
      "Epoch 3/40\n",
      "102/102 [==============================] - 5s 45ms/step - loss: 4.2769 - accuracy: 0.0147 - common_sense_cla: 9.0147 - val_loss: 4.2773 - val_accuracy: 0.0160 - val_common_sense_cla: 8.8580\n",
      "Epoch 4/40\n",
      "102/102 [==============================] - 5s 45ms/step - loss: 4.2768 - accuracy: 0.0141 - common_sense_cla: 8.9408 - val_loss: 4.2781 - val_accuracy: 0.0090 - val_common_sense_cla: 9.0726\n",
      "Epoch 5/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 4.2766 - accuracy: 0.0149 - common_sense_cla: 8.9634 - val_loss: 4.2782 - val_accuracy: 0.0090 - val_common_sense_cla: 9.0656\n",
      "Epoch 6/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 4.2762 - accuracy: 0.0160 - common_sense_cla: 9.0082 - val_loss: 4.2777 - val_accuracy: 0.0104 - val_common_sense_cla: 8.9455\n",
      "Epoch 7/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 4.2053 - accuracy: 0.0226 - common_sense_cla: 8.3116 - val_loss: 4.0574 - val_accuracy: 0.0306 - val_common_sense_cla: 7.6396\n",
      "Epoch 8/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 3.7304 - accuracy: 0.0668 - common_sense_cla: 7.0593 - val_loss: 3.3835 - val_accuracy: 0.1042 - val_common_sense_cla: 6.7569\n",
      "Epoch 9/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 3.0992 - accuracy: 0.1588 - common_sense_cla: 6.0294 - val_loss: 2.9142 - val_accuracy: 0.1896 - val_common_sense_cla: 5.6476\n",
      "Epoch 10/40\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 2.6190 - accuracy: 0.2533 - common_sense_cla: 5.1931 - val_loss: 2.5154 - val_accuracy: 0.2715 - val_common_sense_cla: 5.1503\n",
      "Epoch 11/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 2.2155 - accuracy: 0.3326 - common_sense_cla: 4.5272 - val_loss: 2.2038 - val_accuracy: 0.3160 - val_common_sense_cla: 4.6049\n",
      "Epoch 12/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 1.8852 - accuracy: 0.4150 - common_sense_cla: 3.8347 - val_loss: 2.0094 - val_accuracy: 0.3674 - val_common_sense_cla: 4.1635\n",
      "Epoch 13/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 1.6285 - accuracy: 0.4782 - common_sense_cla: 3.3670 - val_loss: 1.8505 - val_accuracy: 0.3986 - val_common_sense_cla: 3.9396\n",
      "Epoch 14/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 1.4075 - accuracy: 0.5452 - common_sense_cla: 2.8461 - val_loss: 1.7217 - val_accuracy: 0.4292 - val_common_sense_cla: 3.6156\n",
      "Epoch 15/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 1.2358 - accuracy: 0.5854 - common_sense_cla: 2.5983 - val_loss: 1.6305 - val_accuracy: 0.4660 - val_common_sense_cla: 3.2247\n",
      "Epoch 16/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 1.0906 - accuracy: 0.6325 - common_sense_cla: 2.2341 - val_loss: 1.6373 - val_accuracy: 0.4833 - val_common_sense_cla: 3.1774\n",
      "Epoch 17/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.9735 - accuracy: 0.6667 - common_sense_cla: 2.0300 - val_loss: 1.5729 - val_accuracy: 0.5007 - val_common_sense_cla: 2.9240\n",
      "Epoch 18/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.8649 - accuracy: 0.7025 - common_sense_cla: 1.7923 - val_loss: 1.5565 - val_accuracy: 0.5090 - val_common_sense_cla: 2.9160\n",
      "Epoch 19/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.7757 - accuracy: 0.7296 - common_sense_cla: 1.6142 - val_loss: 1.5429 - val_accuracy: 0.5174 - val_common_sense_cla: 2.8983\n",
      "Epoch 20/40\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.6908 - accuracy: 0.7598 - common_sense_cla: 1.4277 - val_loss: 1.4787 - val_accuracy: 0.5410 - val_common_sense_cla: 2.6781\n",
      "Epoch 21/40\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.5911 - accuracy: 0.8014 - common_sense_cla: 1.1980 - val_loss: 1.5173 - val_accuracy: 0.5604 - val_common_sense_cla: 2.5049\n",
      "Epoch 22/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.5424 - accuracy: 0.8111 - common_sense_cla: 1.1586 - val_loss: 1.4579 - val_accuracy: 0.5736 - val_common_sense_cla: 2.4354\n",
      "Epoch 23/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.4976 - accuracy: 0.8282 - common_sense_cla: 0.9957 - val_loss: 1.5644 - val_accuracy: 0.5611 - val_common_sense_cla: 2.4132\n",
      "Epoch 24/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.4400 - accuracy: 0.8505 - common_sense_cla: 0.9056 - val_loss: 1.5912 - val_accuracy: 0.5688 - val_common_sense_cla: 2.4128\n",
      "Epoch 25/40\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 0.3994 - accuracy: 0.8636 - common_sense_cla: 0.8004 - val_loss: 1.5280 - val_accuracy: 0.5986 - val_common_sense_cla: 2.2306\n",
      "Epoch 26/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.3549 - accuracy: 0.8792 - common_sense_cla: 0.7074 - val_loss: 1.5754 - val_accuracy: 0.5792 - val_common_sense_cla: 2.3694\n",
      "Epoch 27/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.3148 - accuracy: 0.8974 - common_sense_cla: 0.5971 - val_loss: 1.6064 - val_accuracy: 0.5910 - val_common_sense_cla: 2.2691\n",
      "Epoch 28/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.2861 - accuracy: 0.9045 - common_sense_cla: 0.5554 - val_loss: 1.7534 - val_accuracy: 0.5819 - val_common_sense_cla: 2.3000\n",
      "Epoch 29/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.2637 - accuracy: 0.9126 - common_sense_cla: 0.5132 - val_loss: 1.7144 - val_accuracy: 0.5993 - val_common_sense_cla: 2.2278\n",
      "Epoch 30/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.2577 - accuracy: 0.9129 - common_sense_cla: 0.4949 - val_loss: 1.7944 - val_accuracy: 0.5931 - val_common_sense_cla: 2.1997\n",
      "Epoch 31/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.2198 - accuracy: 0.9279 - common_sense_cla: 0.4143 - val_loss: 1.7779 - val_accuracy: 0.5965 - val_common_sense_cla: 2.1292\n",
      "Epoch 32/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.1852 - accuracy: 0.9403 - common_sense_cla: 0.3404 - val_loss: 1.8377 - val_accuracy: 0.6042 - val_common_sense_cla: 2.0684\n",
      "Epoch 33/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.1918 - accuracy: 0.9369 - common_sense_cla: 0.3502 - val_loss: 1.9626 - val_accuracy: 0.6042 - val_common_sense_cla: 2.2010\n",
      "Epoch 34/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.1798 - accuracy: 0.9444 - common_sense_cla: 0.3005 - val_loss: 2.0377 - val_accuracy: 0.5924 - val_common_sense_cla: 2.2184\n",
      "Epoch 35/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.1726 - accuracy: 0.9454 - common_sense_cla: 0.3001 - val_loss: 1.9195 - val_accuracy: 0.5903 - val_common_sense_cla: 2.1743\n",
      "Epoch 36/40\n",
      "102/102 [==============================] - 4s 43ms/step - loss: 0.1383 - accuracy: 0.9573 - common_sense_cla: 0.2248 - val_loss: 1.9702 - val_accuracy: 0.6201 - val_common_sense_cla: 1.9833\n",
      "Epoch 37/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.1576 - accuracy: 0.9496 - common_sense_cla: 0.2706 - val_loss: 2.1220 - val_accuracy: 0.6021 - val_common_sense_cla: 2.1028\n",
      "Epoch 38/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.1328 - accuracy: 0.9585 - common_sense_cla: 0.2095 - val_loss: 2.0147 - val_accuracy: 0.6250 - val_common_sense_cla: 1.9653\n",
      "Epoch 39/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.1084 - accuracy: 0.9684 - common_sense_cla: 0.1599 - val_loss: 2.0382 - val_accuracy: 0.6104 - val_common_sense_cla: 2.0549\n",
      "Epoch 40/40\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 0.0901 - accuracy: 0.9757 - common_sense_cla: 0.1126 - val_loss: 2.0859 - val_accuracy: 0.6194 - val_common_sense_cla: 1.9712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x246047de448>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.fit(X,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3705c654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 1s 10ms/step - loss: 2.0150 - accuracy: 0.6017 - common_sense_cla: 2.1254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.015038013458252, 0.6016666889190674, 2.1254167556762695]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c19dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d40ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eff052e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf933f74",
   "metadata": {},
   "source": [
    "720 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da9d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "115db761",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c=[]\n",
    "for i in range(720):\n",
    "    la=np.zeros(720)\n",
    "    la[i]=la[i]+1\n",
    "    for j in range(25):\n",
    "        y_c.append(la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "974da4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c=np.stack(y_c)\n",
    "y_c=np.array(y_c,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d6f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_sense_cla(y_true, y_pred):\n",
    "    d = K.abs(K.argmax(y_true, axis=1) - K.argmax(y_pred, axis=1))\n",
    "    d = tf.cast(d, tf.float32)\n",
    "    return 0.5 * ((1 - (d // 360)) * (d) + (d // 360) * (720 - d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88264a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (14400, 150, 150)\n",
      "Test set: (3600, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "X, X_test, y, y_test = train_test_split(data, y_c, test_size=0.2, random_state=42)\n",
    "print(f\"Train set: {X.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d1ffb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 16)      160       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 36, 36, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 18, 18, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                262208    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 720)               46800     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 332,304\n",
      "Trainable params: 332,304\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(150,150,1)),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\",strides=2),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\",strides=1),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64,activation=keras.layers.LeakyReLU(alpha=0.01)),\n",
    "        layers.Dense(720,activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c446203",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "classification_model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,), metrics=[\"accuracy\",common_sense_cla], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c08e78b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "102/102 [==============================] - 9s 45ms/step - loss: 6.5805 - accuracy: 9.2593e-04 - common_sense_cla: 90.2356 - val_loss: 6.5812 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 89.3837\n",
      "Epoch 2/20\n",
      "102/102 [==============================] - 5s 45ms/step - loss: 6.5793 - accuracy: 0.0018 - common_sense_cla: 89.8209 - val_loss: 6.5830 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 89.5719\n",
      "Epoch 3/20\n",
      "102/102 [==============================] - 5s 45ms/step - loss: 6.5786 - accuracy: 0.0014 - common_sense_cla: 89.9103 - val_loss: 6.5849 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 89.5719\n",
      "Epoch 4/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 6.5781 - accuracy: 0.0017 - common_sense_cla: 89.8167 - val_loss: 6.5865 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 5/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 6.5776 - accuracy: 0.0019 - common_sense_cla: 89.6294 - val_loss: 6.5883 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 6/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 6.5772 - accuracy: 0.0019 - common_sense_cla: 89.6294 - val_loss: 6.5901 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 7/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 6.5767 - accuracy: 0.0012 - common_sense_cla: 90.0473 - val_loss: 6.5918 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 8/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 6.5764 - accuracy: 0.0019 - common_sense_cla: 89.2777 - val_loss: 6.5936 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 9/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 6.5760 - accuracy: 0.0019 - common_sense_cla: 89.5749 - val_loss: 6.5950 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 10/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 6.5757 - accuracy: 0.0019 - common_sense_cla: 89.6294 - val_loss: 6.5965 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 11/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 6.5752 - accuracy: 0.0019 - common_sense_cla: 89.6294 - val_loss: 6.5997 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 12/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 6.5750 - accuracy: 0.0019 - common_sense_cla: 89.6294 - val_loss: 6.6007 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 13/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 6.5748 - accuracy: 0.0015 - common_sense_cla: 89.5605 - val_loss: 6.6038 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 14/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 6.5746 - accuracy: 0.0018 - common_sense_cla: 89.8450 - val_loss: 6.6051 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 15/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 6.5742 - accuracy: 0.0019 - common_sense_cla: 89.6294 - val_loss: 6.6086 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 16/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 6.5740 - accuracy: 0.0019 - common_sense_cla: 89.6294 - val_loss: 6.6107 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 17/20\n",
      "102/102 [==============================] - 5s 45ms/step - loss: 6.5738 - accuracy: 0.0019 - common_sense_cla: 89.6294 - val_loss: 6.6125 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 18/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 6.5736 - accuracy: 0.0019 - common_sense_cla: 89.6294 - val_loss: 6.6143 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 19/20\n",
      "102/102 [==============================] - 5s 44ms/step - loss: 6.5736 - accuracy: 0.0019 - common_sense_cla: 89.6294 - val_loss: 6.6143 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n",
      "Epoch 20/20\n",
      "102/102 [==============================] - 4s 44ms/step - loss: 6.5735 - accuracy: 0.0019 - common_sense_cla: 89.6294 - val_loss: 6.6154 - val_accuracy: 0.0000e+00 - val_common_sense_cla: 90.6976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19bbdbcb788>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.fit(X,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c978cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb89336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9109525",
   "metadata": {},
   "source": [
    "Multi-head models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831161ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fccc699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7cc190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f71bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1871d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa37d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee713594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4ec41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443f578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e5a31f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb17817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa6f2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db467e66",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e799b788",
   "metadata": {},
   "source": [
    "## Task 3: Generative Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce0ed8",
   "metadata": {},
   "source": [
    "In this task, we use MNIST dataset to train the generative models and obtain new figures. We directly call the Tensorflow API to download the dataset. However, the original dataset is also available on this website: <https://deepai.org/dataset/mnist>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f73dea-fe2c-449b-ad2d-ab390c1e07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Conv2DTranspose, Reshape, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc67c38-8af6-4fbf-9d25-bfe3316fd40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocessing\n",
    "X = np.concatenate((x_train, x_test), axis=0)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(X)\n",
    "X = X.astype(\"float32\") / 255.\n",
    "X = X.reshape(X.shape + (1,))\n",
    "print(f\"The shape of dataset: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe542e-7c75-4853-aac1-8a17a1f1f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use modified grid_plot functions in the tutorial           \n",
    "def grid_plot(images, epoch=\"\", name=\"\", n=3, save=False, scale=False):\n",
    "    if scale:\n",
    "        images = (images + 1) / 2.0\n",
    "    for index in range(n * n):\n",
    "        plt.subplot(n, n, 1 + index)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[index])\n",
    "    fig = plt.gcf()\n",
    "    fig.suptitle(name + '  '+ str(epoch), fontsize=14)\n",
    "    if save:\n",
    "        filename = 'results/generated_plot_e%03d_f.png' % (epoch+1)\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af8536d-b0f7-4d8b-8caf-ce7b7839590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "grid_plot(X[np.random.randint(0, 1000, 9)], name=\"MNIST dataset (28 X 28 X 1)\", n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87954b3-74ed-4ea5-ab1a-68b3f311fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use modified build_conv_net and build_deconv_net functions in the tutorial\n",
    "def build_conv_net(in_shape, out_shape, out_activation='sigmoid'):\n",
    "    \"\"\"\n",
    "    Build a basic convolutional network\n",
    "    \"\"\"\n",
    "    in_put = Input(shape=in_shape)\n",
    "    \n",
    "    x = Conv2D(kernel_size=3, filters=32, padding='same', activation='relu')(in_put)\n",
    "    x = Conv2D(kernel_size=3, filters=64, padding='same', activation='relu', strides=(2,2))(x)\n",
    "    x = Conv2D(kernel_size=3, filters=64, padding='same', activation='relu')(x)\n",
    "    x = Conv2D(kernel_size=3, filters=64, padding='same', activation='relu')(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(out_shape, activation=out_activation)(x)\n",
    "    model = tf.keras.Model(in_put, x)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_deconv_net(latent_dim, activation_out='sigmoid'):\n",
    "    \"\"\"\n",
    "    Build a deconvolutional network for decoding/upscaling latent vectors\n",
    "\n",
    "    When building the deconvolutional architecture, usually it is best to use the same layer sizes that \n",
    "    were used in the downsampling network and the Conv2DTranspose layers are used instead of Conv2D layers. \n",
    "    Using identical layers and hyperparameters ensures that the dimensionality of our output matches the\n",
    "    shape of our input images. \n",
    "    \"\"\"\n",
    "    in_put = Input(shape=latent_dim)\n",
    "    x = Dense(14 * 14 * 64)(in_put)\n",
    "    x = Reshape((14, 14, 64))(x) # This matches the output size of the downsampling architecture\n",
    "    x = Conv2DTranspose(32, 3, padding='same', activation='relu', strides=(2,2))(x)\n",
    "    x = Conv2D(filters=1, kernel_size=3, activation=activation_out, padding='same')(x)\n",
    "    model = tf.keras.Model(in_put, x)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f2366",
   "metadata": {},
   "source": [
    "### Convolutional Autoencoder (CAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1be4c8-6459-449c-b197-9d6eee8d35f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAE\n",
    "# Use the build_convolutional_autoencoder function in the tutorial\n",
    "def build_convolutional_autoencoder(data_shape, latent_dim):\n",
    "    encoder = build_conv_net(in_shape=data_shape, out_shape=latent_dim)\n",
    "    decoder = build_deconv_net(latent_dim, activation_out='sigmoid')\n",
    "    autoencoder = tf.keras.Sequential([encoder, decoder])\n",
    "    autoencoder.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return autoencoder\n",
    "\n",
    "# Defining the model dimensions and building it\n",
    "image_size = X.shape[1:]\n",
    "latent_dim = 32\n",
    "num_filters = 64\n",
    "cae = build_convolutional_autoencoder(image_size, latent_dim)\n",
    "\n",
    "for epoch in range(0, 11):\n",
    "    cae.fit(x=X, y=X, epochs=1, batch_size=64, verbose=0)\n",
    "    print('\\nEpoch: ', epoch)\n",
    "    samples = X[:9]\n",
    "    reconstructed = cae.predict(samples, verbose=0)\n",
    "    grid_plot(samples, epoch, name='Original', n=3, save=False)\n",
    "    grid_plot(reconstructed, epoch, name='Reconstructed', n=3, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031b7b6",
   "metadata": {},
   "source": [
    "### Variational Autoencoders (VAEs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97220a0e-6eaa-42fb-b193-8ddf41e54e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Sampling class and the build_vae function in the tutorial\n",
    "class Sampling(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Custom layer for the variational autoencoder\n",
    "    It takes two vectors as input - one for means and other for variances of the latent variables described by a multimodal gaussian\n",
    "    Its output is a latent vector randomly sampled from this distribution\n",
    "    \"\"\"\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_var) * epsilon\n",
    "\n",
    "    \n",
    "def build_vae(data_shape, latent_dim, filters=128):\n",
    "\n",
    "    # Building the encoder - starts with a simple downsampling convolutional network  \n",
    "    encoder = build_conv_net(data_shape, latent_dim*2)\n",
    "    \n",
    "    # Adding special sampling layer that uses the reparametrization trick \n",
    "    z_mean = Dense(latent_dim)(encoder.output)\n",
    "    z_var = Dense(latent_dim)(encoder.output)\n",
    "    z = Sampling()([z_mean, z_var])\n",
    "    \n",
    "    # Connecting the two encoder parts\n",
    "    encoder = tf.keras.Model(inputs=encoder.input, outputs=z)\n",
    "\n",
    "    # Defining the decoder which is a regular upsampling deconvolutional network\n",
    "    decoder = build_deconv_net(latent_dim, activation_out='sigmoid')\n",
    "    vae = tf.keras.Model(inputs=encoder.input, outputs=decoder(z))\n",
    "    \n",
    "    # Adding the special loss term\n",
    "    kl_loss = -0.5 * tf.reduce_sum(z_var - tf.square(z_mean) - tf.exp(z_var) + 1)\n",
    "    vae.add_loss(kl_loss/tf.cast(tf.keras.backend.prod(data_shape), tf.float32))\n",
    "\n",
    "    vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='binary_crossentropy')\n",
    "\n",
    "    return encoder, decoder, vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bf4331-e975-42bb-8c0c-fff00d26daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the VAE model\n",
    "latent_dim = 32\n",
    "encoder, decoder, vae = build_vae(X.shape[1:], latent_dim)\n",
    "\n",
    "# Generate random vectors that we will use to sample our latent space\n",
    "for epoch in range(0, 20):\n",
    "    vae.fit(x=X, y=X, epochs=1, batch_size=16, verbose=1)\n",
    "    latent_vectors = np.random.randn(9, latent_dim)\n",
    "    images = decoder(latent_vectors)\n",
    "    grid_plot(images, epoch, name='VAE generated images (randomly sampled from the latent space)', n=3, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bcad48-d2ae-42a2-8860-2ce28bb8915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 32\n",
    "for i in range(-2, 3):\n",
    "    np.random.seed(42)\n",
    "    latent_vectors = np.tile(np.random.randn(latent_dim), (7, 1))\n",
    "    latent_vectors[:, 9] = np.linspace(-5, 5, num=7)\n",
    "    latent_vectors[:, 26] = i * np.ones(7)\n",
    "\n",
    "    images = decoder(latent_vectors)\n",
    "    plt.figure(figsize = (15, 1.5))\n",
    "    for index in range(7):\n",
    "        plt.subplot(1, 7, index + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[index], aspect='auto')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8570e5ac",
   "metadata": {},
   "source": [
    "### Generative Adversarial Networks (GANs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a1a70-11b7-4fc3-a2fa-8509594f953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use build_gan, run_generator, get_batch, train_gan function in the tutorial\n",
    "def build_gan(data_shape, latent_dim, lr=0.0002, beta_1=0.5):\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=lr, beta_1=beta_1)\n",
    "\n",
    "    # Usually the GAN generator has tanh activation function in the output layer\n",
    "    generator = build_deconv_net(latent_dim, activation_out='tanh')\n",
    "    \n",
    "    # Build and compile the discriminator\n",
    "    discriminator = build_conv_net(in_shape=data_shape, out_shape=1) # Single output for binary classification\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    # End-to-end GAN model for training the generator\n",
    "    discriminator.trainable = False\n",
    "    true_fake_prediction = discriminator(generator.output)\n",
    "    GAN = tf.keras.Model(inputs=generator.input, outputs=true_fake_prediction)\n",
    "    GAN = tf.keras.models.Sequential([generator, discriminator])\n",
    "    GAN.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    return discriminator, generator, GAN\n",
    "\n",
    "\n",
    "def run_generator(generator, n_samples=100):\n",
    "    \"\"\"\n",
    "    Run the generator model and generate n samples of synthetic images using random latent vectors\n",
    "    \"\"\"\n",
    "    latent_dim = generator.layers[0].input_shape[-1]\n",
    "    generator_input = np.random.randn(n_samples, latent_dim[1])\n",
    "\n",
    "    return generator.predict(generator_input)\n",
    "    \n",
    "\n",
    "def get_batch(generator, dataset, batch_size=64):\n",
    "    \"\"\"\n",
    "    Gets a single batch of samples (X) and labels (y) for the training the discriminator.\n",
    "    One half from the real dataset (labeled as 1s), the other created by the generator model (labeled as 0s).\n",
    "    \"\"\"\n",
    "    batch_size //= 2 # Split evenly among fake and real samples\n",
    "\n",
    "    fake_data = run_generator(generator, n_samples=batch_size)\n",
    "    real_data = dataset[np.random.randint(0, dataset.shape[0], batch_size)]\n",
    "\n",
    "    X = np.concatenate([fake_data, real_data], axis=0)\n",
    "    y = np.concatenate([np.zeros([batch_size, 1]), np.ones([batch_size, 1])], axis=0)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def train_gan(generator, discriminator, gan, dataset, latent_dim, n_epochs=20, batch_size=64):\n",
    "\n",
    "    batches_per_epoch = int(dataset.shape[0] / batch_size / 2)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in range(batches_per_epoch):\n",
    "            \n",
    "            # 1) Train discriminator both on real and synthesized images\n",
    "            X, y = get_batch(generator, dataset, batch_size=batch_size)\n",
    "            discriminator_loss = discriminator.train_on_batch(X, y)\n",
    "\n",
    "            # 2) Train generator (note that now the label of synthetic images is reversed to 1)\n",
    "            X_gan = np.random.randn(batch_size, latent_dim)\n",
    "            y_gan = np.ones([batch_size, 1])\n",
    "            generator_loss = gan.train_on_batch(X_gan, y_gan)\n",
    "            \n",
    "        noise = np.random.randn(16, latent_dim)\n",
    "        images = generator.predict(noise)\n",
    "        grid_plot(images, epoch, name='GAN generated images', n=3, save=False, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f0309-dae4-42cf-8dc1-1692f34dd6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and train the model (need around 10 epochs to start seeing some results)\n",
    "latent_dim = 256\n",
    "discriminator, generator, gan = build_gan(X.shape[1:], latent_dim)\n",
    "\n",
    "train_gan(generator, discriminator, gan, X, latent_dim, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110af65a-1881-49c8-a765-b6f960e7ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "\n",
    "np.random.seed(13)\n",
    "latent_vectors = np.tile(np.random.randn(latent_dim), (7, 1))\n",
    "latent_vectors[:, 0] = np.linspace(-30, 30, num=7)\n",
    "\n",
    "images = generator(latent_vectors)\n",
    "plt.figure(figsize = (15, 1.5))\n",
    "for index in range(7):\n",
    "    plt.subplot(1, 7, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index], aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170806b-223f-4ab8-978f-b271171f51c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "\n",
    "np.random.seed(13)\n",
    "latent_vectors = np.tile(np.random.randn(latent_dim), (7, 1))\n",
    "latent_vectors[:, 119] = np.linspace(-30, 30, num=7)\n",
    "\n",
    "images = generator(latent_vectors)\n",
    "plt.figure(figsize = (15, 1.5))\n",
    "for index in range(7):\n",
    "    plt.subplot(1, 7, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index], aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce67ad6-604c-428b-bfd7-c17a7e35968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "\n",
    "np.random.seed(13)\n",
    "latent_vectors = np.tile(np.random.randn(latent_dim), (7, 1))\n",
    "latent_vectors[:, 125] = np.linspace(0, 30, num=7)\n",
    "\n",
    "images = generator(latent_vectors)\n",
    "plt.figure(figsize = (15, 1.5))\n",
    "for index in range(7):\n",
    "    plt.subplot(1, 7, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index], aspect='auto')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
